if (mymax2 > mymax) { mymax <- mymax2 }
# make a red histogram of the forecast errors, with the normally distributed data overlaid:
mybins <- seq(mymin, mymax, mybinsize)
hist(forecasterrors, col="red", freq=FALSE, breaks=mybins)
# freq=FALSE ensures the area under the histogram = 1
# generate normally distributed data with mean 0 and standard deviation mysd
myhist <- hist(mynorm, plot=FALSE, breaks=mybins)
# plot the normal curve as a blue line on top of the histogram of forecast errors:
points(myhist$mids, myhist$density, type="l", col="blue", lwd=2)
}
plotForecastErrors(rainseriesforecasts2$residuals)
skirts <- scan("http://robjhyndman.com/tsdldata/roberts/skirts.dat",skip=5)
skirtsseries <- ts(skirts,start=c(1866))
plot.ts(skirtsseries)
skirtsseriesforecasts <- HoltWinters(skirtsseries, gamma=FALSE)
skirtsseriesforecasts
skirtsseriesforecasts$SSE
plot(skirtsseriesforecasts)
HoltWinters(skirtsseries, gamma=FALSE, l.start=608, b.start=9)
skirtsseriesforecasts2 <- forecast.HoltWinters(skirtsseriesforecasts, h=19)
plot.forecast(skirtsseriesforecasts2)
acf(skirtsseriesforecasts2$residuals, lag.max=20)
Box.test(skirtsseriesforecasts2$residuals, lag=20, type="Ljung-Box")
plot.ts(skirtsseriesforecasts2$residuals) # make a time plot
plotForecastErrors(skirtsseriesforecasts2$residuals)
souvenirtimeseriesforecasts <- HoltWinters(logsouvenirtimeseries)
souvenirtimeseriesforecasts
souvenirtimeseriesforecasts$SSE
plot(souvenirtimeseriesforecasts)
souvenirtimeseriesforecasts2 <- forecast.HoltWinters(souvenirtimeseriesforecasts, h=48)
plot.forecast(souvenirtimeseriesforecasts2)
acf(souvenirtimeseriesforecasts2$residuals, lag.max=20)
Box.test(souvenirtimeseriesforecasts2$residuals, lag=20, type="Ljung-Box")
plot.ts(souvenirtimeseriesforecasts2$residuals) # make a time plot
plotForecastErrors(souvenirtimeseriesforecasts2$residuals) # make a histogram
?matchIt
library("TTR")
library("forecast")
skirts <- scan("http://robjhyndman.com/tsdldata/roberts/skirts.dat",skip=5)
skirtsseries <- ts(skirts,start=c(1866))
plot.ts(skirtsseries)
skirtsseriesforecasts <- HoltWinters(skirtsseries, gamma=FALSE)
skirtsseriesforecasts
skirtsseriesforecasts$SSE
plot(skirtsseriesforecasts)
HoltWinters(skirtsseries, gamma=FALSE, l.start=608, b.start=9)
skirtsseriesforecasts2 <- forecast.HoltWinters(skirtsseriesforecasts, h=19)
plot.forecast(skirtsseriesforecasts2)
acf(skirtsseriesforecasts2$residuals, lag.max=20)
Box.test(skirtsseriesforecasts2$residuals, lag=20, type="Ljung-Box")
plot.ts(skirtsseriesforecasts2$residuals) # make a time plot
plotForecastErrors(skirtsseriesforecasts2$residuals)
plotForecastErrors <- function(forecasterrors) {
# make a histogram of the forecast errors:
mybinsize <- IQR(forecasterrors)/4
mysd <- sd(forecasterrors)
mymin <- min(forecasterrors) - mysd*5
mymax <- max(forecasterrors) + mysd*3
# generate normally distributed data with mean 0 and standard deviation mysd
mynorm <- rnorm(10000, mean=0, sd=mysd)
mymin2 <- min(mynorm)
mymax2 <- max(mynorm)
if (mymin2 < mymin) { mymin <- mymin2 }
if (mymax2 > mymax) { mymax <- mymax2 }
# make a red histogram of the forecast errors, with the normally distributed data overlaid:
mybins <- seq(mymin, mymax, mybinsize)
hist(forecasterrors, col="red", freq=FALSE, breaks=mybins)
# freq=FALSE ensures the area under the histogram = 1
# generate normally distributed data with mean 0 and standard deviation mysd
myhist <- hist(mynorm, plot=FALSE, breaks=mybins)
# plot the normal curve as a blue line on top of the histogram of forecast errors:
points(myhist$mids, myhist$density, type="l", col="blue", lwd=2)
}
plotForecastErrors(skirtsseriesforecasts2$residuals)
skirtsseriesdiff1 <- diff(skirtsseries, differences=1)
plot.ts(skirtsseriesdiff1)
skirtsseriesdiff2 <- diff(skirtsseries, differences=2)
plot.ts(skirtsseriesdiff2)
install.packages("fUnitRoots")
library(fUnitRoots)
?fUnitRoots
??fUnitRoots
kings <- scan("http://robjhyndman.com/tsdldata/misc/kings.dat",skip=3)
kingstimeseries <- ts(kings)
kingstimeseries
kingstimeseriesSMA3 <- SMA(kingstimeseries,n=3)
plot.ts(kingstimeseriesSMA3)
kingstimeseriesSMA8 <- SMA(kingstimeseries,n=8)
plot.ts(kingstimeseriesSMA8)
kingtimeseriesdiff1 <- diff(kingstimeseries, differences=1)
plot.ts(kingtimeseriesdiff1)
acf(kingtimeseriesdiff1, lag.max=20) # plot a correlogram
acf(kingtimeseriesdiff1, lag.max=20, plot=FALSE) # get the autocorrelation values
pacf(kingtimeseriesdiff1, lag.max=20) # plot a partial correlogram
pacf(kingtimeseriesdiff1, lag.max=20, plot=FALSE) # get the partial autocorrelation values
auto.arima(kings)
volcanodust <- scan("http://robjhyndman.com/tsdldata/annual/dvi.dat", skip=1)
volcanodustseries <- ts(volcanodust,start=c(1500))
plot.ts(volcanodustseries)
acf(volcanodustseries, lag.max=20) # plot a correlogram
acf(volcanodustseries, lag.max=20, plot=FALSE) # get the values of the autocorrelations
pacf(volcanodustseries, lag.max=20)
pacf(volcanodustseries, lag.max=20, plot=FALSE)
auto.arima(volcanodust)
auto.arima(volcanodust,ic="bic")
kingstimeseriesarima <- arima(kingstimeseries, order=c(0,1,1)) # fit an ARIMA(0,1,1) model
kingstimeseriesarima
forecast.Arima(kingstimeseriesarima,h=5, level=c(99.5))
kingstimeseriesforecasts <- forecast.Arima(kingstimeseriesarima, h=5)
kingstimeseriesforecasts
plot.forecast(kingstimeseriesforecasts)
acf(kingstimeseriesforecasts$residuals, lag.max=20)
Box.test(kingstimeseriesforecasts$residuals, lag=20, type="Ljung-Box")
plot.ts(kingstimeseriesforecasts$residuals) # make time plot of forecast errors
plotForecastErrors(kingstimeseriesforecasts$residuals) # make a histogram
volcanodustseriesarima <- arima(volcanodustseries, order=c(2,0,0))
volcanodustseriesarima
volcanodustseriesforecasts <- forecast.Arima(volcanodustseriesarima, h=31)
volcanodustseriesforecasts
plot.forecast(volcanodustseriesforecasts)
volcanodustseries
volcanodustseriesforecasts
plot(volcanodustseries$fitted)
plot(volcanodustarima)
plot(volcanodustseriesarima$x,col="red")
lines(fitted(volcanodustseriesarima),col="blue")
volcanodustseriesarima <- Arima(volcanodustseries, order=c(2,0,0))
plot(volcanodustseriesarima$x,col="red")
lines(fitted(volcanodustseriesarima),col="blue")
plot.forecast(volcanodustseriesforecasts)
acf(volcanodustseriesforecasts$residuals, lag.max=20)
Box.test(volcanodustseriesforecasts$residuals, lag=20, type="Ljung-Box")
plot.ts(volcanodustseriesforecasts$residuals) # make time plot of forecast errors
plotForecastErrors(volcanodustseriesforecasts$residuals) # make a histogram
mean(volcanodustseriesforecasts$residuals)
data(AirPassengers)
AP <- AirPassengers
AP
plot(AP, ylab = "Passengers (1000's)")
layout(1:2)
plot(aggregate(AP))
boxplot(AP ~ cycle(AP))
plot(cbind(Elec.ts, Beer.ts, Choc.ts))
AP.elec <- ts.intersect(AP, Elec.ts)
plot(as.vector(AP), as.vector(Elec),
xlab = "Air passengers / 1000's",
ylab = "Electricity production / MWh")
Z.92.96 <- window(Z.ts, start = c(1992, 1), end = c(1996, 1))
Global.annual <- aggregate(Global.ts, FUN = mean)
library(ISLR); library(ggplot2); library(caret)
install.packages(ISLR)
install.packages("ISLR")
library(ISLR); library(ggplot2); library(caret)
data(Wage)
inTrain <- createDataPartition(y=Wage$wage, p=0.7,list=FALSE)
training <- Wage[inTrain,]
testing <- Wage[-inTrain,]
dim(training); dim(testing)
featurePlot(x=training[,c("age","education","jobclass")],y=training$wage,plot="pairs")
qplot(age,wage,data=training)
qplot(age,wage,data=training,colour=jobclass)
qq<- qplot(age,wage,data=training,colour=education)
qq + geom_smooth(method="lm",y~x)
qq + geom_smooth(method="lm",formula=y~x)
library(Hmisc)
cutWage <- cut2(training$wage, g=3)
table(cutWage)
p1 <- qplot(cutWage,age,data=training, fill=cutWage,geom=c("boxplot"))
p1
p2 <- qplot(cutWage,age,data=training, fill=cutWage,geom=c("boxplot","jitter"))
grid.arrange(p1,p2,ncol=2)
t1 <- table(cutWage,training$jobclass)
t1
prop.table(t1,1)
qplot(wage,colour=education,data=training,geom="density")
data(spam)
preobj <- preProcess(training[,-58],method=c("centre","scale"))
library(caret)
data(spam)
preobj <- preProcess(training[,-58],method=c("center","scale"))
data(iris)
library(ggplot2)
table(iris$Species)
inTrain <- createDataPartition(y=iris$Species,p=0.7,list=FALSE)
traniing <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training);dim(testing)
library(caret)
inTrain <- createDataPartition(y=iris$Species,p=0.7,list=FALSE)
traniing <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training);dim(testing)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training);dim(testing)
rm(traniing)
qplot(Petal.Width,Sepal.Width,colour=Species,data=training)
modFit <- train(Species ~.,method="rpart",data=training)
print(modFit$finalModel)
plot(modFit$finalModel,uniform=TRUE)
text(modFit$finalModel,unse.n=TRUE,all=TRUE,cex=0.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rattle")
library(rattle)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
inTrain <- createDataPartition(y=iris$Species,p=0.7,list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training);dim(testing)
View(segmentationOriginal)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.7,list=FALSE)
View(segmentationOriginal)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training);dim(testing)
View(inTrain)
training <- segmentationOriginal[segmentationOriginal$Case,]
testing <- segmentationOriginal[-segmentationOriginal$Case,]
dim(training);dim(testing)
training <- segmentationOriginal[segmentationOriginal$Case=="Train",]
testing <- segmentationOriginal[segmentationOriginal$Case=="Test",]
dim(training);dim(testing)
inTrain <- createDataPartition(y=segmentationOriginal$Case,p=0.7,list=FALSE)
training <- segmentationOriginal[inTrain,]
testing <- segmentationOriginal[-inTrain,]
dim(training);dim(testing)
set.seed(125)
modFit <- train(Case ~.,method="rpart",data=training)
print(modFit$finalModel)
plot(modFit$finalModel,uniform=TRUE)
text(modFit$finalModel,unse.n=TRUE,all=TRUE,cex=0.8)
training <- segmentationOriginal[segmentationOriginal$Case=="Train",]
testing <- segmentationOriginal[segmentationOriginal$Case=="Test",]
dim(training);dim(testing)
set.seed(125)
modFit <- train(Case ~.,method="rpart",data=training)
modFit <- train(Class ~.,method="rpart",data=training)
print(modFit$finalModel)
plot(modFit$finalModel,uniform=TRUE)
text(modFit$finalModel,unse.n=TRUE,all=TRUE,cex=0.8)
predict(modFit,newdata=testing)
library(pgmm)
data(olive)
olive = olive[,-1]
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
View(olive)
modFit <- train(Area ~.,method="rpart",data=olive)
newdata <- as.data.frame(t(colMeans(olive)))
predict(modFit,newdata=newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
View(trainSA)
names(trainSA)
set.seed(13234)
modFit <- train(chd ~ age+alcohol+obesity+tobacco+typea+ldl,method="glm",family="binomial",data=olive)
set.seed(13234)
modFit <- train(chd ~ age+alcohol+obesity+tobacco+typea+ldl,method="glm",family="binomial",data=trainSA)
print(modFit$finalModel)
missClass <- function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA$chd,predict(modFit,trainSA))
missClass(testSA$chd,predict(modFit,testSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
View(vowel.test)
vowel.train$y <- factor(vowel.train$y)
vowel.test$y <- factor(vowel.test$y)
?varImp
varImp(ModFit)
set.seed(33833)
modFit <- train(y ~.,method="rf",prox=TRUE,data=vowel.train)
rfNews
()
rfNews()
varImp(modFit)
##=====================##
## READING IN THE DATA ##
##=====================##
library(zoo)
library(ggplot2)
library(plyr)
library(dplyr)
library(reshape2)
library(stargazer)
library(micEcon)
library(quantreg)
library(McSpatial)
library(quantmod)
#setwd("C:/Users/Laurie/OneDrive/Documents/BING/METRICS/PhD Proposal Readings/Art Price Index")
setwd("C:\\Users\\Laurie\\OneDrive\\Documents\\BING\\PhD Proposal Readings\\Art Price Index\\R Code")
#library(rJava)
#library(xlsxjars)
#library(xlsx)
#artdata <- read.xlsx("Auction database.xlsx",sheetIndex=1,header=TRUE)
artdata <- read.csv("Auction database.csv", header=TRUE, sep=";",na.strings = "", skipNul = TRUE,
colClasses=c("character","numeric","numeric","numeric","numeric","factor","factor","factor","character",
"factor","factor","factor","character","factor","factor","factor","numeric","character",
"numeric","numeric","numeric","numeric","numeric","numeric"))
##===================##
## CLEANING THE DATA ##
##===================##
artdata$date <- as.Date(artdata$date)
artdata$med_code <- factor(artdata$med_code, labels=c("Drawing", "Watercolour", "Oil", "Acrylic", "Print/Woodcut",
"Mixed Media","Sculpture","Photography", "Other"))
artdata$ah_code <- factor(artdata$ah_code, labels=c("5th Avenue","Ashbeys","Bernardi","Bonhams","Russell Kaplan",
"Stephan Welz","Strauss","Christies"))
artdata$timedummy <- factor(as.yearqtr(artdata$date, "%Y-%m-%d"))
#artdata$timedummy <- factor(paste(artdata$year, artdata$quarter, sep="_")
#dummies = model.matrix(~artdata$timedummy)
#For every unique value in the string column, create a new 1/0 column
#This is what Factors do "under-the-hood" automatically when passed to function requiring numeric data
artdata$lnprice <- log(artdata$price)
artdata$lnarea <- log(artdata$area)
artdata$lnarea2 <- artdata$lnarea*artdata$lnarea
#artdata$lnsculpt_area <- 0
#artdata$lnsculpt_area[na.omit(artdata$med_code==7)] <- artdata$lnarea   #inteaction term: sculptures often only reported with 1 dimension (height)
artdata$lnsculpt_area <- ifelse(artdata$med_code=="Sculpture", artdata$lnarea, 0)
artdata$counter <- as.numeric(artdata$timedummy)
#source(themes)
#source(materials)
#change reference category with relevel()
#artdata$ah_code <- relevel(artdata$ah_code, ref = "Stephan Welz & Co")
#artdata$artist <- relevel(artdata$artist, ref = "Battiss, Walter Whall")
#artdata$med_code <- relevel(artdata$med_code, ref = "Oil")
#head(artdata)
#str(artdata)
##----------------------
##Rank Artists by Volume
##----------------------
#Rank by Total Volume (all)
rankings <- count(artdata, artist)
rankings$rank_all <- dense_rank(desc(rankings$n))    #rank by density, with no gaps between ranks
#rankings$rank_all <- min_rank(desc(rankings$n))     #equivalent to rank(ties.method = "min")
rankings$rank_total <- row_number(desc(rankings$n))  #equivalent to rank(ties.method = "first")
rankings$n <- NULL
#rankings$rank_all <- factor(rankings$rank_all, labels=c)
#artdata <- merge(artdata, tel, by.x="artist", by.y="artist")
##Rank by Rolling 5-year window
for(i in 1:11) {
teller <- 1998+i
som <- count(artdata[(artdata$year>teller & artdata$year<(teller+6)),], artist)
som$rank_new <- dense_rank(desc(som$n))
# the alternative is to rank by row_number or min_rank
som$n <- NULL
colnames(som) <- c("artist", paste0("rank_", i))
rankings <- merge(rankings, som, by.x="artist", by.y="artist",all.x=TRUE)
}
#Rank Update
som <- count(artdata[(artdata$counter>42 & artdata$counter<63),], artist)
som$rank_new <- dense_rank(desc(som$n))  # rank by equivalent to rank(ties.method = "first")
# the alternative is to rank by row_number or min_rank
som$n <- NULL
colnames(som) <- c("artist", "rank_update")
rankings <- merge(rankings, som, by.x="artist", by.y="artist",all.x=TRUE)
##Rank by Annual Volume
for(i in 1:16) {
teller <- 1999+i
som <- count(artdata[(artdata$year==teller),], artist)
som$rank_new <- dense_rank(desc(som$n))
# the alternative is to rank by row_number or min_rank
som$n <- NULL
colnames(som) <- c("artist", paste0("rank_y", teller))
rankings <- merge(rankings, som, by.x="artist", by.y="artist",all.x=TRUE)
}
##Rank by 2-year Volume
for(i in 1:8) {
teller <- 1998+(i*2-1)
som <- count(artdata[(artdata$year>teller & artdata$year<(teller+3)),], artist)
som$rank_new <- dense_rank(desc(som$n))
# the alternative is to rank by row_number or min_rank
som$n <- NULL
colnames(som) <- c("artist", paste0("rank_a", i))
rankings <- merge(rankings, som, by.x="artist", by.y="artist",all.x=TRUE)
}
artdata <- merge(artdata, rankings, by.x="artist", by.y="artist",all.x=TRUE)
modeldata <- subset(artdata, artdata$rank_all<101)
list_expl_vars <- c("lnarea","ah_code","med_code","lnsculpt_area","dum_signed", "dum_dated",
"nr_works","artist","timedummy")
expl_vars <- as.formula(paste("lnprice~",paste(list_expl_vars,collapse="+")))
model_100 <- lm(expl_vars, data=modeldata)
#The betaj coefficients are plugged into equation 5
#This equation is calculated for every artist pair that consists of the base artist and another.
rep <- list()
rep[[1]] <- 1
for(i in 2:(max(artdata$rank_total))) {
##maak dit 'n function waaroor jy sapply?????
list_vars <- c(list_expl_vars,"price")
#geometric average of paintings by artist y
y <- subset(artdata[,list_vars], artdata$rank_total==1)
y <- y[!rowSums(is.na(y)), ]
py <-  exp(mean(log(y$price)))
#py <- max(cumprod(y$price^(1/nrow(y))))
ym1 <- subset(artdata[,list_vars], artdata$rank_total==i)
ym1 <- ym1[!rowSums(is.na(ym1)), ]
pym1 <-  exp(mean(log(ym1$price)))
#pym1 <- max(cumprod(ym1$price^(1/nrow(ym1))))
sbx <- 0
#average of characteristics time implicit attribute price
xy <- mean(y$lnarea)
xym1 <- mean(ym1$lnarea)
b <- summary(model_100)$coefficients[grepl("lnarea", rownames(summary(model_100)$coefficients)),1]
bx <- b*(xym1-xy)
sbx <- sbx + bx
xy <- mean(y$lnsculpt_area)
xym1 <- mean(ym1$lnsculpt_area)
b <- summary(model_100)$coefficients[grepl("lnsculpt_area", rownames(summary(model_100)$coefficients)),1]
bx <- b*(xym1-xy)
sbx <- sbx + bx
xy <- mean(y$nr_works)
xym1 <- mean(ym1$nr_works)
b <- summary(model_100)$coefficients[grepl("nr_works", rownames(summary(model_100)$coefficients)),1]
bx <- b*(xym1-xy)
sbx <- sbx + bx
xy <- mean(as.numeric(y$dum_signed)-1)
xym1 <- mean(as.numeric(ym1$dum_signed)-1)
b <- summary(model_100)$coefficients[grepl("dum_signed", rownames(summary(model_100)$coefficients)),1]
bx <- b*(xym1-xy)
sbx <- sbx + bx
xy <- mean(as.numeric(y$dum_dated)-1)
xym1 <- mean(as.numeric(ym1$dum_dated)-1)
b <- summary(model_100)$coefficients[grepl("dum_dated", rownames(summary(model_100)$coefficients)),1]
bx <- b*(xym1-xy)
sbx <- sbx + bx
auc_house <- c("Ashbeys","Bernardi","Bonhams","Russell Kaplan","Stephan Welz","Strauss","Christies")
for(j in auc_house) {
xy <- mean(as.numeric(y$ah_code==j))
xym1 <- mean(as.numeric(ym1$ah_code==j))
b <- summary(model_100)$coefficients[grepl(j, rownames(summary(model_100)$coefficients)),1]
bx <- b*(xym1-xy)
sbx <- sbx + bx
}
medium <- c("Watercolour","Oil","Acrylic","Print/Woodcut","Mixed Media","Sculpture","Photography","Other")
for(k in medium) {
xy <- mean(as.numeric(y$med_code==k))
xym1 <- mean(as.numeric(ym1$med_code==k))
b <- summary(model_100)$coefficients[grepl(k, rownames(summary(model_100)$coefficients)),1]
bx <- b*(xym1-xy)
sbx <- sbx + bx
}
rep[i] <- (pym1/py)/exp(sbx)
}
#reputation <- as.matrix(rep)
for(i in 1:(max(artdata$rank_total))) {
artdata$reputation[(artdata$rank_total==i)] <- rep[i]
}
artdata$reputation <- as.numeric(unlist(artdata$reputation))
artdata$lnrep <- log(artdata$reputation)
g <- ggplot(artdata, aes(x=lnrep, y=lnprice))
g <- g + geom_point(size = 2, alpha = 0.5, aes(colour = med_code))
g <- g + geom_smooth()
g <- g + ylab("log of Price")
g <- g + xlab("log of Reputation")
g
list_expl_vars <- c("lnarea","ah_code","med_code","lnsculpt_area","dum_signed","dum_dated",
"nr_works","lnrep","timedummy")
modeldata <- artdata
expl_vars <- as.formula(paste("lnprice~",paste(list_expl_vars,collapse="+")))
model_all <- lm(expl_vars, data=modeldata)
stargazer(model_all, omit=c("timedummy"),omit.labels = "Quarterly dummies",type = "text")
summary(model_all)
time_results <- summary(model_all)$coefficients[grepl("time", rownames(summary(model_all)$coefficients)),1]
time_results <- as.data.frame(time_results)
time_results$index_all <- exp(time_results$time_results)*100
View(time_results)
time_results$se <- summary(model_all)$coefficients[grepl("time", rownames(summary(model_all)$coefficients)),2]
time_results$ci.up <- exp(time_results$index_all+2*time_results$se)*100
time_results$ci.up <- time_results$time_results+2*time_results$se
time_results$ci.up <- exp(time_results$time_results+2*time_results$se)*100
time_results$ci.low <- exp(time_results$time_results-2*time_results$se)*100
index_plot <- melt(time_results[,c(2,4,5)], id="Date")  # convert to long format
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable))
g <- g + geom_point(size = 3)
g <- g + geom_line()
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.position="bottom") + theme(legend.title=element_blank())
g
time_results$Date <- c("2000Q2","2000Q3","2000Q4","2001Q1","2001Q2","2001Q3","2001Q4","2002Q1","2002Q2","2002Q3","2002Q4",
"2003Q1","2003Q2","2003Q3","2003Q4","2004Q1","2004Q2","2004Q3","2004Q4","2005Q1","2005Q2","2005Q3","2005Q4",
"2006Q1","2006Q2","2006Q3","2006Q4","2007Q1","2007Q2","2007Q3","2007Q4","2008Q1","2008Q2","2008Q3","2008Q4",
"2009Q1","2009Q2","2009Q3","2009Q4","2010Q1","2010Q2","2010Q3","2010Q4","2011Q1","2011Q2","2011Q3","2011Q4",
"2012Q1","2012Q2","2012Q3","2012Q4","2013Q1","2013Q2","2013Q3","2013Q4","2014Q1","2014Q2","2014Q3","2014Q4",
"2015Q1","2015Q2")
time_results$Date <- factor(time_results$Date)
index_plot <- melt(time_results[,c(2,4,5,6)], id="Date")  # convert to long format
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable))
g <- g + geom_point(size = 3)
g <- g + geom_line()
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.position="bottom") + theme(legend.title=element_blank())
g
stargazer(model_all, omit=c("timedummy"),omit.labels = "Quarterly dummies",type = "text")[1,1]
