---
title: "The South African Art Market"
subtitle: "Explosive Behaviour"
author: Laurie Binge
date: "15 February 2016"
output:
  beamer_presentation:
    includes:
      in_header: mystyle.tex
    theme: "CambridgeUS"
    colortheme: "dolphin"
    fonttheme: "structurebold" 
    toc: true
    slide_level: 2
---


#Introduction

## The South African Art Market

Surge in popularity of Modern and Contemporary South African art 

Huge increase in prices in run-up to Great Recession   

Record prices at international and local auctions   

- Irma Stern's *"Arab Priest"* sold for £2.7m in 2011 Bonhams in London 
- Irma Stern's *"Two Arabs"* sold for R19m by Strauss & Co

Prompted many claims of a "bubble"" in the art market   
  
Objectives:  

1) Construct indicators of art market prices over time
2) Test for a "bubble" in the SA art market

```{r cleaning, echo=FALSE, results='hide', message=FALSE, warning=FALSE, cache = TRUE}
##=====================##
## READING IN THE DATA ##
##=====================##
suppressMessages(library(zoo))
suppressMessages(library(ggplot2))
suppressMessages(library(plyr))
suppressMessages(library(dplyr))
suppressMessages(library(reshape2))
suppressMessages(library(stargazer))
suppressMessages(library(micEcon))
suppressMessages(library(quantreg))
suppressMessages(library(McSpatial))
suppressMessages(library(quantmod))
suppressMessages(library(xtable))
suppressMessages(library(scales))
suppressMessages(library(tseries))
suppressMessages(library(urca))

setwd("C:\\Users\\Laurie\\OneDrive\\Documents\\BING\\PhD Proposal Readings\\Art Price Index\\R Code")
artdata <- read.csv("Auction database.csv", header=TRUE, sep=",",na.strings = "", skipNul = TRUE, 
                    colClasses=c("character","numeric","numeric","numeric","numeric","factor","factor","factor","character",
                                 "factor","factor","factor","character","factor","factor","factor","numeric","character",
                                 "numeric","numeric","numeric","numeric","numeric","numeric"))

##===================##
## CLEANING THE DATA ##
##===================##
artdata$date <- as.Date(artdata$date)
artdata$med_code <- factor(artdata$med_code, labels=c("Drawing", "Watercolour", "Oil", "Acrylic", "Print/Woodcut",
                                                      "Mixed Media","Sculpture","Photography", "Other"))
artdata$ah_code <- factor(artdata$ah_code, labels=c("5th Avenue","Ashbeys","Bernardi","Bonhams","Russell Kaplan",
                                                    "Stephan Welz","Strauss","Christies"))
artdata$timedummy <- factor(as.yearqtr(artdata$date, "%Y-%m-%d"))
artdata$lnprice <- log(artdata$price)
artdata$lnarea <- log(artdata$area)
artdata$lnarea2 <- artdata$lnarea*artdata$lnarea
#inteaction term: sculptures often only reported with 1 dimension (height)
artdata$lnsculpt_area <- ifelse(artdata$med_code=="Sculpture", artdata$lnarea, 0)
artdata$counter <- as.numeric(artdata$timedummy)

##----------------------
##Rank Artists by Volume
##----------------------
#Rank by Total Volume (all)
rankings <- count(artdata, artist)
rankings$rank_all <- dense_rank(desc(rankings$n))    #rank by density, with no gaps (ties = equal)
rankings$rank_total <- row_number(desc(rankings$n))  #equivalent to rank(ties.method = "first")
rankings$n <- NULL

artdata <- merge(artdata, rankings, by.x="artist", by.y="artist",all.x=TRUE)
```

## Arab Priest - Irma Stern
![alt text](Arab_Priest.png)

# Data

## South African Art Auction Data

AuctionVault/Citadel auction data:

- 2000-2015
- 8 auction houses
- 50,560 sales 
- 4,361 artists
- Various characteristics for each records

Public auction prices vs. private prices   

Bought-in lots


## Turnover
```{r figure1, echo=FALSE, cache = TRUE, fig.height=4, fig.width=6.5, fig.cap="Turnover (sum of hammer prices) by auction house (2000-2015)"}
#Plot turnover by auction house
artplot <- aggregate(artdata$hammer_price, by=list(artdata$year,artdata$ah_code), FUN = sum, na.rm=TRUE)
g <- ggplot(artplot, aes(x=Group.1, y=x,fill=Group.2))
g <- g + geom_bar(stat="identity")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + scale_fill_discrete(name="Auction House")
g <- g + scale_y_continuous(labels=comma)
g <- g + ylab("Turnover (Sum of Hammer Price)")
g <- g + xlab("Date")
g
```

## Sales and Prices
```{r figure2, echo=FALSE, cache = TRUE, fig.height=4, fig.width=6.5, fig.cap="Median hammer prices and total sales (lots) at auction (2000-2015)"}
#Plot total sales and annual median price
artplot1 <- aggregate(artdata$hammer_price, by=list(artdata$year), length)
artplot2 <- aggregate(artdata$hammer_price, by=list(artdata$year), FUN = median, na.rm=TRUE)
artplot <- merge(artplot1, artplot2, by="Group.1",all.x=TRUE)
names(artplot) <- c("Date","Total Sales","Median Price")
artplot <- melt(artplot, id="Date") 
g <- ggplot(artplot, aes(x=Date,value,colour=variable,fill=variable))
g <- g + geom_bar(subset=.(variable=="Total Sales"),stat="identity")
g <- g + geom_line(subset=.(variable=="Median Price"),size=1)
g <- g + theme(legend.position="bottom") + theme(legend.title=element_blank())
g 
```

# Methodology

## Measurement Methodology

Accurate measurement is difficult:

- Assets are heterogeneous (unique) & involve large transaction costs 
- Less liquid than traditional assets & low transaction frequency
- Small part of the overall market is traded at any given time 
- Composition & quality not constant

Estimation methodologies:

1. Naïve or central tendency methods
2. Repeat sales regressions
3. Hedonic regressions
4. Hybrid models


##Central Tendency methods
Average (median) price over time

Slight improvement by stratification e.g. ABSA

- Median price 
- Stratified Fisher indices

```{r naive, echo=FALSE, results='hide', message=FALSE, warning=FALSE, cache = TRUE}
naive_index <- aggregate(artdata$price, by=list(artdata$timedummy), FUN=median, na.rm=TRUE)
naive_index$index <- naive_index$x
naive_index$index <- naive_index$index/naive_index[1,2]*100
naive_index$index <- as.numeric(naive_index$index)
colnames(naive_index) <- c("Date","Median","Index_Naive")

#Stratify by artist and medium
#get quantity and median price per group per quarter     
strat_p <- aggregate(artdata$price, by=list(artdata$timedummy, artdata$artist, artdata$med_code), FUN=mean)
strat_q <- aggregate(artdata$price, by=list(artdata$timedummy, artdata$artist, artdata$med_code), FUN=sum)
strat_q$x <- strat_q$x/strat_p$x        #the count q
strat_p <- aggregate(artdata$price, by=list(artdata$timedummy, artdata$artist, artdata$med_code), FUN=median)

chain2 <- function(strat_p, strat_q, kwartaal1,kwartaal2) {
    strat_p1 <- subset(strat_p, strat_p$Group.1==kwartaal1)
    strat_q1 <- subset(strat_q, strat_q$Group.1==kwartaal1)
    strat_p2 <- subset(strat_p, strat_p$Group.1==kwartaal2)
    strat_q2 <- subset(strat_q, strat_q$Group.1==kwartaal2)
    #get sample of median prices and quantities for specific artist for the two quarters
    strat_pc <- merge(strat_p1, strat_p2, by=c("Group.2","Group.3"))
    strat_qc <- merge(strat_q1, strat_q2, by=c("Group.2","Group.3"))
    #Laspeyres (keeps quantity weights fixed at base)
    Lasp <- sum(strat_pc$x.y*strat_qc$x.x,na.rm=TRUE)/sum(strat_pc$x.x*strat_qc$x.x,na.rm=TRUE)
    #Paasche (keeps quantity weights fixed at end)
    Paas <- sum(strat_pc$x.y*strat_qc$x.y,na.rm=TRUE)/sum(strat_pc$x.x*strat_qc$x.y,na.rm=TRUE)
    return(c(Lasp,Paas))
}

datum <- c("2000 Q1","2000 Q2","2000 Q3","2000 Q4","2001 Q1","2001 Q2","2001 Q3","2001 Q4","2002 Q1","2002 Q2","2002 Q3","2002 Q4","2003 Q1","2003 Q2","2003 Q3","2003 Q4","2004 Q1","2004 Q2","2004 Q3","2004 Q4","2005 Q1","2005 Q2","2005 Q3","2005 Q4","2006 Q1","2006 Q2","2006 Q3","2006 Q4","2007 Q1","2007 Q2","2007 Q3","2007 Q4","2008 Q1","2008 Q2","2008 Q3","2008 Q4","2009 Q1","2009 Q2","2009 Q3","2009 Q4","2010 Q1","2010 Q2","2010 Q3","2010 Q4","2011 Q1","2011 Q2","2011 Q3","2011 Q4","2012 Q1","2012 Q2","2012 Q3","2012 Q4","2013 Q1","2013 Q2","2013 Q3","2013 Q4","2014 Q1","2014 Q2","2014 Q3","2014 Q4","2015 Q1","2015 Q2","2015 Q3","2015 Q4")

ketting2 <- chain2(strat_p,strat_q,datum[1],datum[2])
ketting2 <- rbind(ketting2,chain2(strat_p,strat_q,datum[2],datum[3]))
for(i in 3:63) {
    ketting2 <- rbind(ketting2,chain2(strat_p,strat_q,datum[i],datum[(i+1)]))
}
ketting2 <- as.data.frame(ketting2)
ketting2$V3 <- sqrt(ketting2[,1]*ketting2[,2])  #Fisher index is the geometric mean
ketting2$V4[1] <- ketting2$V3[1]*100
for(i in 2:63) {                                #use the growth rates to generate the index
    ketting2$V4[i] <- ketting2$V4[(i-1)]*ketting2$V3[i]
}
ketting2$Date <- as.factor(datum[-1])
colnames(ketting2) <- c("Las","Paas","Fisher","Index_Fisher","Date")
```

##Central Tendency Indices
```{r figure3, echo=FALSE, cache = TRUE, fig.height=4, fig.width=6.5, fig.cap="Central tendency South African art price indices (2000Q1=100)"}
index_plot <- merge(ketting2, naive_index, by.x="Date", by.y="Date",all.x=TRUE)
index_plot <- index_plot[,c(1,5,7)]
index_plot <- melt(index_plot, id="Date")  # convert to long format
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable)) 
g <- g + geom_point(size = 1) 
g <- g + geom_line()
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.position="bottom") + theme(legend.title=element_blank())
g
```

##Hedonic regression methodology
Prices described by characteristics:
$$\ln P_{it} =\alpha+\sum_{j=1}^z\beta_jX_{ij}+\sum_{t=1}^\tau\gamma_tD_{it}+\epsilon_{it}$$

Strip observable characteristics to obtain "standard asset" 

Control for quality by attributing implicit prices to characteristics

Omitted variable & misspecification bias

##Artwork Attributes
- Artist reputation
$$\text{Artist reputation index} = \frac{\prod_{i=1}^n(P_{i,y})^\frac{1}{n}/\prod_{i=1}^m(P_{i,0})^\frac{1}{m}}{\exp \left[\sum_{j=1}^z\beta_j(\sum_{i=0}^n \frac{X_{ij,y}}{n}- \sum_{i=1}^m \frac{X_{ij,0}}{m})\right]} $$
- Size
- Auction houses
- Mediums
- Authenticity dummies
- Number of works in the lot
- Date dummies

```{r reputation, eval=FALSE, echo=FALSE, results='hide', message=FALSE, warning=FALSE}
##------------------------------------------##
##---ARTIST REPUTATION VARIABLE (Kraussl)---##
##------------------------------------------##
modeldata <- subset(artdata, artdata$rank_all<101)
list_expl_vars <- c("lnarea","ah_code","med_code","lnsculpt_area","dum_signed", "dum_dated",  
                    "nr_works","artist","timedummy")
expl_vars <- as.formula(paste("lnprice~",paste(list_expl_vars,collapse="+")))
model_100 <- lm(expl_vars, data=modeldata)

#Second step: betaj coefficients are plugged into equation for every artist pair (base & another) 
rep <- list()
rep[[1]] <- 1
for(i in 2:(max(artdata$rank_total))) {
    list_vars <- c(list_expl_vars,"price")
    
    #geometric mean of paintings by artist y
    y <- subset(artdata[,list_vars], artdata$rank_total==1)
    y <- y[!rowSums(is.na(y)), ]
    py <-  exp(mean(log(y$price)))  
    ym1 <- subset(artdata[,list_vars], artdata$rank_total==i)
    ym1 <- ym1[!rowSums(is.na(ym1)), ]
    pym1 <-  exp(mean(log(ym1$price)))
    sbx <- 0
    
    #average of characteristics time implicit attribute price
    xy <- mean(y$lnarea)
    xym1 <- mean(ym1$lnarea)   
    b <- summary(model_100)$coefficients[grepl("lnarea", rownames(summary(model_100)$coefficients)),1]
    bx <- b*(xym1-xy)   
    sbx <- sbx + bx
    
    xy <- mean(y$lnsculpt_area)
    xym1 <- mean(ym1$lnsculpt_area)   
    b <- summary(model_100)$coefficients[grepl("lnsculpt_area", rownames(summary(model_100)$coefficients)),1]
    bx <- b*(xym1-xy)   
    sbx <- sbx + bx
    
    xy <- mean(y$nr_works)
    xym1 <- mean(ym1$nr_works)   
    b <- summary(model_100)$coefficients[grepl("nr_works", rownames(summary(model_100)$coefficients)),1]
    bx <- b*(xym1-xy)   
    sbx <- sbx + bx
    
    xy <- mean(as.numeric(y$dum_signed)-1)
    xym1 <- mean(as.numeric(ym1$dum_signed)-1)   
    b <- summary(model_100)$coefficients[grepl("dum_signed", rownames(summary(model_100)$coefficients)),1]
    bx <- b*(xym1-xy)   
    sbx <- sbx + bx
    
    xy <- mean(as.numeric(y$dum_dated)-1)
    xym1 <- mean(as.numeric(ym1$dum_dated)-1)   
    b <- summary(model_100)$coefficients[grepl("dum_dated", rownames(summary(model_100)$coefficients)),1]
    bx <- b*(xym1-xy)   
    sbx <- sbx + bx
    
    auc_house <- c("Ashbeys","Bernardi","Bonhams","Russell Kaplan","Stephan Welz","Strauss","Christies")  
    for(j in auc_house) {
        xy <- mean(as.numeric(y$ah_code==j))
        xym1 <- mean(as.numeric(ym1$ah_code==j))  
        b <- summary(model_100)$coefficients[grepl(j, rownames(summary(model_100)$coefficients)),1]
        bx <- b*(xym1-xy)   
        sbx <- sbx + bx
    }
    
    medium <- c("Watercolour","Oil","Acrylic","Print/Woodcut","Mixed Media","Sculpture","Photography","Other")  
    for(k in medium) {
        xy <- mean(as.numeric(y$med_code==k))
        xym1 <- mean(as.numeric(ym1$med_code==k))   
        b <- summary(model_100)$coefficients[grepl(k, rownames(summary(model_100)$coefficients)),1]
        bx <- b*(xym1-xy)   
        sbx <- sbx + bx
    }
    rep[i] <- (pym1/py)/exp(sbx)
}

for(i in 1:(max(artdata$rank_total))) { 
    artdata$reputation[(artdata$rank_total==i)] <- rep[i]
}

artdata$reputation <- as.numeric(unlist(artdata$reputation))
artdata$lnrep <- log(artdata$reputation)
```

```{r hedonicrep, echo=FALSE, results='hide', message=FALSE, warning=FALSE, cache = TRUE}
#------------------------------------------------------------------------------------------------------------------------------
#Load pre-calculated dataset (for speed) from API_3.R
artdata <- read.csv("artdata_lnrep.csv", header=TRUE)

#The result: index of average price per artist adjusted for quality, relative to the base artist 
#It can replace the artist dummies as a continuous variable in a second regression of equation 1 

#-------------------
# FULL SAMPLE MODEL
#-------------------
full_model <- function(artdata, list_expl_vars=c("lnarea","ah_code","med_code","lnsculpt_area","dum_signed", "dum_dated",  
                                                 "nr_works","artist","timedummy")) {
    if("artist" %in% list_expl_vars) { 
        modeldata <- subset(artdata, artdata$rank_all<max(artdata$rank_all,na.rm=TRUE))
    } else modeldata <- artdata
    expl_vars <- as.formula(paste("lnprice~",paste(list_expl_vars,collapse="+")))
    model_all <- lm(expl_vars, data=modeldata)
    time_results <- summary(model_all)$coefficients[grepl("time", rownames(summary(model_all)$coefficients)),1]
    time_results <- as.data.frame(time_results)
    time_results$index_all <- exp(time_results$time_results)*100
    return(time_results)
}

#-----------------------------
# OVERLAPPING PERIODS (1-year)
#-----------------------------
overlap1y_model <- function(artdata, list_expl_vars=c("lnarea","ah_code","med_code","lnsculpt_area","dum_signed", "dum_dated",  
                                                      "nr_works","artist","timedummy")) {
    expl_vars <- as.formula(paste("lnprice~",paste(list_expl_vars,collapse="+")))
    res_list <- list()
    for(i in 1:16) {
        if("artist" %in% list_expl_vars) {
            modeldata <- subset(artdata, artdata[,(44+i)]<max(artdata[,(44+i)],na.rm=TRUE))
        } else modeldata <- artdata
        modeldata <- subset(modeldata, modeldata$counter>(i*4-5)& modeldata$counter<(i*4+1))
        model <- lm(expl_vars, data=modeldata)  
        res_list[[i]] <- summary(model)$coefficients[grepl("time", rownames(summary(model)$coefficients)),1]
    }
    #Merge all results
    if("artist" %in% list_expl_vars) {
        overlap <- time_results
    } else overlap <- rep_results
    overlap$time_results <- NULL
    overlap <- merge(overlap, res_list[[1]], by="row.names", all=TRUE)
    overlap[,3] <- exp(overlap[,3])*100
    for(i in 2:16) {
        overlap <- merge(overlap, res_list[[i]], by.x = "Row.names", by.y = "row.names", all=TRUE)
        overlap[,(i+2)] <- exp(overlap[i+2])*100
    } 
    #Calculate index
    overlap$ind <- overlap[,3]
    overlap[2,19] <- overlap[3,19]*overlap[2,2]/overlap[3,2]   #Interpolate
    overlap$teller <- c(3,3,3,4,4,4,4,5,5,5,5,6,6,6,6,7,7,7,7,8,8,8,8,9,9,9,9,10,10,10,10,11,11,11,11,12,12,12,12,
                        13,13,13,13,14,14,14,14,15,15,15,15,16,16,16,16,17,17,17,17,18,18,18,18)
    for(i in 3:62) {
        j <- overlap[(i+1),20]
        if(is.na(overlap[i,j])) {
            overlap[(i+1),19] <- overlap[i,19]*overlap[(i+1),j]/100
        } else { 
            overlap[(i+1),19] <- overlap[i,19]*overlap[(i+1),j]/overlap[i,j] 
        }   
    }
    colnames(overlap) <- c("Date","Index_Full","Index_m1","Index_m2","Index_m3","Index_m4","Index_m5","Index_m6",
                           "Index_m7","Index_m8","Index_m9","Index_m10","Index_m11","Index_m12","Index_m13",
                           "Index_m14","Index_m15","Index_m16","Index_Adjacent1y","teller")
    overlap$Date <- c("2000Q2","2000Q3","2000Q4","2001Q1","2001Q2","2001Q3","2001Q4","2002Q1","2002Q2","2002Q3","2002Q4",
                      "2003Q1","2003Q2","2003Q3","2003Q4","2004Q1","2004Q2","2004Q3","2004Q4","2005Q1","2005Q2","2005Q3","2005Q4",
                      "2006Q1","2006Q2","2006Q3","2006Q4","2007Q1","2007Q2","2007Q3","2007Q4","2008Q1","2008Q2","2008Q3","2008Q4",
                      "2009Q1","2009Q2","2009Q3","2009Q4","2010Q1","2010Q2","2010Q3","2010Q4","2011Q1","2011Q2","2011Q3","2011Q4",
                      "2012Q1","2012Q2","2012Q3","2012Q4","2013Q1","2013Q2","2013Q3","2013Q4","2014Q1","2014Q2","2014Q3","2014Q4",
                      "2015Q1","2015Q2","2015Q3","2015Q4")
    overlap$Date <- factor(overlap$Date)
    return(overlap)
}

#-----------------------------
# OVERLAPPING PERIODS (2-year)
#-----------------------------
overlap2y_model <- function(artdata, list_expl_vars=c("lnarea","ah_code","med_code","lnsculpt_area","dum_signed", "dum_dated",  
                                                      "nr_works","artist","timedummy")) {
    expl_vars <- as.formula(paste("lnprice~",paste(list_expl_vars,collapse="+")))
    res_list <- list()
    for(i in 1:8) {
        if("artist" %in% list_expl_vars) {
            modeldata <- subset(artdata, artdata[,(60+i)]<max(artdata[,(60+i)],na.rm=TRUE))
        } else modeldata <- artdata
        modeldata <- subset(modeldata, modeldata$counter>(i*8-9)& modeldata$counter<(i*8+1))
        model <- lm(expl_vars, data=modeldata)  
        res_list[[i]] <- summary(model)$coefficients[grepl("time", rownames(summary(model)$coefficients)),1]
    }
    #Merge all results
    if("artist" %in% list_expl_vars) {
        overlap2 <- time_results
    } else overlap2 <- rep_results
    overlap2$time_results <- NULL
    overlap2 <- merge(overlap2, res_list[[1]], by="row.names", all=TRUE)
    overlap2[,3] <- exp(overlap2[,3])*100
    for(i in 2:8) {
        overlap2 <- merge(overlap2, res_list[[i]], by.x = "Row.names", by.y = "row.names", all=TRUE)
        overlap2[,(i+2)] <- exp(overlap2[i+2])*100
    } 
    #Calculate index
    overlap2$ind <- overlap2[,3]
    overlap2[2,11] <- overlap2[3,11]*overlap2[2,2]/overlap2[3,2]   #Interpolate
    overlap2$teller <- c(3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,
                         7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10)
    for(i in 7:62) {
        j <- overlap2[(i+1),12]
        if(is.na(overlap2[i,j])) {
            overlap2[(i+1),11] <- overlap2[i,11]*overlap2[(i+1),j]/100
        } else { 
            overlap2[(i+1),11] <- overlap2[i,11]*overlap2[(i+1),j]/overlap2[i,j] 
        }   
    }
    colnames(overlap2) <- c("Date","Index_Full","Index_m1","Index_m2","Index_m3","Index_m4","Index_m5",
                            "Index_m6","Index_m7","Index_m8","Index_Adj2y","teller")
    overlap2$Date <- c("2000Q2","2000Q3","2000Q4","2001Q1","2001Q2","2001Q3","2001Q4","2002Q1","2002Q2","2002Q3","2002Q4",
                       "2003Q1","2003Q2","2003Q3","2003Q4","2004Q1","2004Q2","2004Q3","2004Q4","2005Q1","2005Q2","2005Q3","2005Q4",
                       "2006Q1","2006Q2","2006Q3","2006Q4","2007Q1","2007Q2","2007Q3","2007Q4","2008Q1","2008Q2","2008Q3","2008Q4",
                       "2009Q1","2009Q2","2009Q3","2009Q4","2010Q1","2010Q2","2010Q3","2010Q4","2011Q1","2011Q2","2011Q3","2011Q4",
                       "2012Q1","2012Q2","2012Q3","2012Q4","2013Q1","2013Q2","2013Q3","2013Q4","2014Q1","2014Q2","2014Q3","2014Q4",
                       "2015Q1","2015Q2","2015Q3","2015Q4")
    overlap2$Date <- factor(overlap2$Date)
    return(overlap2)
}

#----------------------
#ROLLING 5-YEAR WINDOWS
#----------------------

rolling_model <- function(artdata, list_expl_vars=c("lnarea","ah_code","med_code","lnsculpt_area","dum_signed", "dum_dated",  
                                                    "nr_works","artist","timedummy")) {
    expl_vars <- as.formula(paste("lnprice~",paste(list_expl_vars,collapse="+")))
    res_list <- list()
    for(i in 1:12) {
        if("artist" %in% list_expl_vars) {
            modeldata <- subset(artdata, artdata[,(32+i)]<max(artdata[,(32+i)],na.rm=TRUE))
        } else modeldata <- artdata
        modeldata <- subset(modeldata, modeldata$counter>(i*4-4)&modeldata$counter<(i*4+17))
        model <- lm(expl_vars, data=modeldata)  
        summary(model)
        res_list[[i]] <- summary(model)$coefficients[grepl("time", rownames(summary(model)$coefficients)),1]
    }
    
    #Merge all results
    if("artist" %in% list_expl_vars) {
        rolling <- time_results
    } else rolling <- rep_results
    rolling$time_results <- NULL
    rolling <- merge(rolling, res_list[[1]], by="row.names", all=TRUE)
    rolling[,3] <- exp(rolling[,3])*100
    for(i in 2:12) {
        rolling <- merge(rolling, res_list[[i]], by.x = "Row.names", by.y = "row.names", all=TRUE)
        rolling[,(i+2)] <- exp(rolling[i+2])*100
    }    
    
    #Calculate index
    rolling$ind <- rolling[,3]
    rolling[2,15] <- rolling[3,15]*rolling[2,2]/rolling[3,2]  #interpolate
    rolling$teller <- c(3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,5,5,5,5,6,6,6,6,7,7,7,7,8,8,8,8,9,9,9,9,
                        10,10,10,10,11,11,11,11,12,12,12,12,13,13,13,13,14,14,14,14)
    for(i in 19:62) {  #chaining
        j <- rolling[(i+1),16]
        rolling[(i+1),15] <- rolling[i,15]*rolling[(i+1),j]/rolling[i,j]
    }
    
    colnames(rolling) <- c("Date","Index_Full","Index_m1","Index_m2","Index_m3","Index_m4","Index_m5","Index_m6",
                           "Index_m7","Index_m8","Index_m9","Index_m10","Index_m11","Index_m12","Index_Rolling","teller")
    rolling$Date <- c("2000Q2","2000Q3","2000Q4","2001Q1","2001Q2","2001Q3","2001Q4","2002Q1","2002Q2","2002Q3","2002Q4",
                      "2003Q1","2003Q2","2003Q3","2003Q4","2004Q1","2004Q2","2004Q3","2004Q4","2005Q1","2005Q2","2005Q3","2005Q4",
                      "2006Q1","2006Q2","2006Q3","2006Q4","2007Q1","2007Q2","2007Q3","2007Q4","2008Q1","2008Q2","2008Q3","2008Q4",
                      "2009Q1","2009Q2","2009Q3","2009Q4","2010Q1","2010Q2","2010Q3","2010Q4","2011Q1","2011Q2","2011Q3","2011Q4",
                      "2012Q1","2012Q2","2012Q3","2012Q4","2013Q1","2013Q2","2013Q3","2013Q4","2014Q1","2014Q2","2014Q3","2014Q4",
                      "2015Q1","2015Q2","2015Q3","2015Q4")
    rolling$Date <- factor(rolling$Date)
    return(rolling)
}

#========================================================================================
list_expl_vars <- c("lnarea","ah_code","med_code","lnsculpt_area","dum_signed","dum_dated",  
                    "nr_works","lnrep","timedummy")

rep_results <- full_model(artdata,list_expl_vars)
suppressMessages(rep_overlap1 <- overlap1y_model(artdata,list_expl_vars))
suppressMessages(rep_overlap2 <- overlap2y_model(artdata,list_expl_vars))
suppressMessages(rep_rolling <- rolling_model(artdata,list_expl_vars))
```

## Adjacent Periods

```{r figure4, echo=FALSE, warning=FALSE, cache = TRUE, fig.height=4, fig.width=6.5, fig.cap="Chain-linked two-year adjacent period art price index"}
index_plot <- melt(rep_overlap2[,c(-2,-12)], id="Date")  # convert to long format
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable)) 
g <- g + geom_point(size = 1) 
g <- g + geom_line()
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.title=element_blank())
g 
```

## Hedonic Estimation Results

```{r figure5, echo=FALSE, cache = TRUE, fig.height=4, fig.width=6.5, fig.cap="Hedonic South African art price indices (2000Q1=100)"}
hedonic_indices <- rep_overlap1[,c(1,2)]
colnames(hedonic_indices) <- c("Date","Hedonic_Full")
hedonic_indices <- cbind(hedonic_indices,Adjacent_1y=rep_overlap1[,19])
hedonic_indices <- cbind(hedonic_indices,Adjacent_2y=rep_overlap2[,11])
hedonic_indices <- cbind(hedonic_indices,Rolling=rep_rolling[,15])

index_plot <- melt(hedonic_indices, id="Date")  # convert to long format
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable)) 
g <- g + geom_point(size = 1) 
g <- g + geom_line()
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.position="bottom") + theme(legend.title=element_blank())
g 
```


##Repeat Sales Regression Method
Track repeated sale of a specific asset over time (e.g. Case-Shiller)

Estimate average return on set of assets in each period 
$$\ln\frac{P_{t+1}}{P_t} =\sum_{i=1}^t\gamma_id_{i}+\epsilon_{i}$$

Controls for all factors contributing to the variation in price growth 

But wasteful of data (resale may only occur infrequently)

Possible sample selection bias

- e.g. low-quality houses often sell more frequently


##Hybrid Models: The Pseudo Repeat Sales Method
Limited number of repeat sales pairs (561) 

- perfect matches (*Wheat Field with Crows*)

Match similar assets over time (*Sunflowers* series)

Address problem of lack of repeat sales

Create (many) pseudo sales pairs:

- Hedonic matching by artist and medium 
- Set distance metric

```{r repeatsales, echo=FALSE, results='hide', message=FALSE, warning=FALSE, cache = TRUE}
##=====================##
## REPEAT SALES METHOD ##
##=====================##
#check for duplicates (how many)
sum(duplicated(artdata[,c("artist","title","med_code","area","dum_signed","dum_dated")]))

allDup <- function (value)  { #identify duplicated values
    duplicated(value) | duplicated(value, fromLast = TRUE)
}
rsartdata <- artdata[allDup(artdata[,c("artist","title","med_code","area","dum_signed","dum_dated")]),]
rsartdata <- transform(rsartdata, id = as.numeric(interaction(artist,factor(title),med_code,factor(area),factor(dum_signed),
                                                              factor(dum_dated), drop=TRUE)))

repdata <- repsaledata(rsartdata$lnprice,rsartdata$counter,rsartdata$id)    #transform the data to sales pairs
repeatsales <- repsale(repdata$price0,repdata$time0,repdata$price1,repdata$time1,mergefirst=2,
                       graph=FALSE,graph.conf=TRUE,conf=.95)                 #generate the repeat sales index
repeatsales_index <- exp(as.data.frame(repeatsales$pindex))*100
repeatsales_index$Date <- c("2000Q4","2001Q1","2001Q2","2001Q3","2001Q4","2002Q1","2002Q2","2002Q4",
"2003Q1","2003Q2","2003Q4","2004Q1","2004Q2","2004Q4","2005Q1","2005Q2","2005Q3","2005Q4",
"2006Q1","2006Q2","2006Q3","2006Q4","2007Q2","2007Q3","2007Q4","2008Q1","2008Q2","2008Q3","2008Q4",
"2009Q1","2009Q2","2009Q3","2009Q4","2010Q1","2010Q2","2010Q3","2010Q4","2011Q1","2011Q2","2011Q3","2011Q4","2012Q1","2012Q2","2012Q3","2012Q4","2013Q1","2013Q2","2013Q3","2013Q4","2014Q1","2014Q2","2014Q3","2014Q4","2015Q1","2015Q2","2015Q3","2015Q4")
```

##Index construction methodology
Repeat sales regressions on pseudo pairs:
$$\ln P_{bsj} - \ln P_{arj}=\sum_{k=1}^K\beta_k(X_{bsjk}-X_{arjk})+\sum_{t=0}^\tau\gamma_td_{t}+\epsilon_{srabj}$$

Control for many possible omitted variables by taking first differences

- includes perfect matches
- interaction and squared terms
- finer mediums, materials (e.g. linocuts)

```{r psRSsample, echo=FALSE, eval= FALSE, results='hide', message=FALSE, warning=FALSE, cache = TRUE}
##------------------------------------------------------------------
##--------------- Pseudo Repeat Sales ------------------------------
##------------------------------------------------------------------
#The distance metric between any two sales (across the intervening time period) is the 
#absolute value of the difference between the two predicted hedonic log values. 
#The threshold for this distance metric can be customised. 
#At one extreme, one can choose to select only one pair with the smallest value of the distance metric. 

#match per artist by hedonic function
list_expl_vars <- c("lnarea","ah_code","med_code","lnsculpt_area","dum_signed","dum_dated",  
                    "nr_works","timedummy")
expl_vars <- as.formula(paste("lnprice~",paste(list_expl_vars,collapse="+")))

ps.RSsample <- function(threshold) {
    teller <-0
    repdata <- data.frame()
    rartdata <- subset(artdata,artdata$rank_all<max(artdata$rank_all,na.rm=TRUE))  #exclude artists with one sale
    keep <- c("lnprice","artist","title","lnarea","ah_code","med_code","lnsculpt_area","dum_signed","dum_dated",  
              "nr_works","timedummy","counter")
    rartdata <- rartdata[,names(rartdata) %in% keep]
    rartdata <- rartdata[complete.cases(rartdata),]  
    
    #Rank total again for new sample
    rankings <- count(rartdata, artist)
    rankings$rank_total <- row_number(desc(rankings$n))
    rartdata <- merge(rartdata, rankings, by.x="artist", by.y="artist",all.x=TRUE)
    
    for(k in 1:max(rartdata$rank_total)) { 
        modeldata <- subset(rartdata, rartdata$rank_total==k)
        modeldata$med_code <- factor(modeldata$med_code)
        modeldata$ah_code <- factor(modeldata$ah_code)
        modeldata$dum_signed <- factor(modeldata$dum_signed)
        modeldata$dum_dated <- factor(modeldata$dum_dated)
        modeldata$timedummy <- factor(modeldata$timedummy)
        
        #if there is only one factor level => make it a zero
        if(length(levels(modeldata$med_code))==1)   { modeldata$med_code <- as.numeric(0) }
        if(length(levels(modeldata$ah_code))==1)    { modeldata$ah_code <- as.numeric(0) }
        if(length(levels(modeldata$dum_signed))==1) { modeldata$dum_signed <- as.numeric(0) }
        if(length(levels(modeldata$dum_dated))==1)  { modeldata$dum_dated <- as.numeric(0)   }
        
        if(length(levels(modeldata$timedummy))!=1) {   #if there were sales in more than one period
            model <- lm(expl_vars, data=modeldata, na.action = na.exclude)
            newdata <- modeldata
            newdata$timedummy <- newdata$timedummy[1]  #turn time dummy off by making them all the same
            modeldata <- cbind(modeldata,fitted=predict.lm(model,newdata=newdata))  #add predicted value
            
            for(i in 1:nrow(modeldata)) {  #give items below threshold the same id
                modeldata$id <- 0
                teller <- teller + 1
                modeldata$id[i] <- teller
                medium <- modeldata$med_code[i]
                modeldata$distance <- abs(modeldata$fitted[i]-modeldata$fitted)  #distance metric
                #distances <- cbind(distances,modeldata$distance)
                if(threshold=="nearest"){  #nearest match if same medium
                    #modeldata$id[(modeldata$distance==min(modeldata$distance[modeldata[,"id"]==0 & modeldata[,"med_code"]==medium],na.rm=TRUE))] <- teller
                    modeldata$id[(modeldata$distance==0 & modeldata[,"med_code"]==medium)] <- teller
                } else {                   #if same medium and distance smaller than threshold
                    modeldata$id[(modeldata$distance<threshold & modeldata[,"med_code"]==medium)] <- teller
                } 
                if(sum(modeldata[,"id"]!=0)>1) {
                    repdata <- rbind(repdata,modeldata[modeldata[,"id"]!=0, ])
                }
            }
        }
    }
    #transform the data to pseudo repeat sales pairs (for all attributes)
    fullrep <- cbind(repsaledata(repdata$lnprice,repdata$counter,repdata$id),
                     repsaledata(repdata$artist,repdata$counter,repdata$id)[,4:5],
                     repsaledata(repdata$title,repdata$counter,repdata$id)[,4:5],
                     repsaledata(repdata$lnarea,repdata$counter,repdata$id)[,4:5],
                     repsaledata(repdata$med_code,repdata$counter,repdata$id)[,4:5],
                     repsaledata(repdata$ah_code,repdata$counter,repdata$id)[,4:5],
                     repsaledata(repdata$lnsculpt_area,repdata$counter,repdata$id)[,4:5],
                     repsaledata(repdata$dum_signed,repdata$counter,repdata$id)[,4:5],
                     repsaledata(repdata$dum_dated,repdata$counter,repdata$id)[,4:5],
                     repsaledata(repdata$nr_works,repdata$counter,repdata$id)[,4:5])
    
    colnames(fullrep) <- c("id","time0","time1","price0","price1","artist0","artist1","title0","title1","area0","area1",
                           "med_code0","med_code1","ah_code0","ah_code1","sculpt0","sculpt1","sign0","sign1","date0","date1",
                           "nr0","nr1")
    return(fullrep)
}

ps.RSsample_1 <- ps.RSsample(0.01)
ps.RSsample_2 <- ps.RSsample(0.001)
ps.RSsample_n <- ps.RSsample("nearest") 
```

```{r psRS, echo=FALSE, results='hide', message=FALSE, warning=FALSE, cache = TRUE}
ps.RSsample_1 <- read.csv("psRSsample_0.01.csv", header=TRUE, sep=",",na.strings = "NA", skipNul = TRUE)
ps.RSsample_2 <- read.csv("psRSsample_0.001.csv", header=TRUE, sep=",",na.strings = "NA", skipNul = TRUE)
ps.RSsample_n <- read.csv("psRSsample_n.csv", header=TRUE, sep=",",na.strings = "NA", skipNul = TRUE)

ps.RS <- function(fullrep) {
    dy <- fullrep$price1 - fullrep$price0
    timevar <- levels(factor(c(fullrep$time0, fullrep$time1)))
    nt = length(timevar)
    n = length(dy)
    xmat <- array(0, dim = c(n, nt - 1))
    for (j in seq(1 + 1, nt)) {
        xmat[, j - 1] <- ifelse(fullrep$time1 == timevar[j], 1, xmat[, j - 1])
        xmat[, j - 1] <- ifelse(fullrep$time0 == timevar[j],-1, xmat[, j - 1])
    }
    colnames(xmat) <- paste("Time", seq(1 + 1, nt))
    fit <- lm(dy ~ xmat + 0)
    
    fullrep$med_code0[is.na(fullrep$med_code0)] <- "Oil"
    fullrep$med_code1[is.na(fullrep$med_code1)] <- "Oil"
    fullrep$ah_code0[is.na(fullrep$ah_code0)] <- "Strauss"
    fullrep$ah_code1[is.na(fullrep$ah_code1)] <- "Strauss"
    
    darea <- fullrep$area1 - fullrep$area0
    
    med0 <- model.matrix(~fullrep$med_code0)
    med1 <- model.matrix(~fullrep$med_code1)
    dmed <- med1 - med0
    
    ah0 <- model.matrix(~fullrep$ah_code0)
    ah1 <- model.matrix(~fullrep$ah_code1)
    dah <- ah1 - ah0
    
    dsculpt <- fullrep$sculpt1 - fullrep$sculpt0
    dnr <- fullrep$nr1 - fullrep$nr0
    
    sign0 <- model.matrix(~fullrep$sign0)
    sign1 <- model.matrix(~fullrep$sign1)
    dsign <- sign1 - sign0
    
    date0 <- model.matrix(~fullrep$date0)
    date1 <- model.matrix(~fullrep$date1)
    ddate <- date1 - date0

    ps.RS <- lm(dy ~ darea + dah + dsculpt + dnr + dsign + ddate + xmat + 0)
    ps.RS_results <- summary(ps.RS)$coefficients[grepl("Time", rownames(summary(ps.RS)$coefficients)),1]
    ps.RS_results <- as.data.frame(ps.RS_results)
    ps.RS_results$index_all <- exp(ps.RS_results$ps.RS_results)*100
    ps.RS_results$pairs <- nrow(fullrep)
    
    return(ps.RS_results)
}

ps.RS_1 <- ps.RS(ps.RSsample_1)
ps.RS_2 <- ps.RS(ps.RSsample_2)
ps.RS_n <- ps.RS(ps.RSsample_n)

Dates <- c("2000Q2","2000Q3","2000Q4","2001Q1","2001Q2","2001Q3","2001Q4","2002Q1","2002Q2","2002Q3","2002Q4",
           "2003Q1","2003Q2","2003Q3","2003Q4","2004Q1","2004Q2","2004Q3","2004Q4","2005Q1","2005Q2","2005Q3","2005Q4",
           "2006Q1","2006Q2","2006Q3","2006Q4","2007Q1","2007Q2","2007Q3","2007Q4","2008Q1","2008Q2","2008Q3","2008Q4",
           "2009Q1","2009Q2","2009Q3","2009Q4","2010Q1","2010Q2","2010Q3","2010Q4","2011Q1","2011Q2","2011Q3","2011Q4",
           "2012Q1","2012Q2","2012Q3","2012Q4","2013Q1","2013Q2","2013Q3","2013Q4","2014Q1","2014Q2","2014Q3","2014Q4",
           "2015Q1","2015Q2","2015Q3","2015Q4")

ps.RS_1$Date <- Dates
ps.RS_2$Date <- Dates
ps.RS_n$Date <- Dates[-2]

rep_indices <- merge(repeatsales_index, ps.RS_1, by="Date", all=TRUE)
rep_indices <- merge(rep_indices, ps.RS_2, by="Date", all=TRUE)
rep_indices <- merge(rep_indices, ps.RS_n, by="Date", all=TRUE)
rep_indices <- rep_indices[,c(1,2,4,7,10)]
colnames(rep_indices) <- c("Date","Repeat Sales","ps.RS(1%)","ps.RS(0.1%)","ps.RS(nearest)")       
```


##Pseudo Repeat Sales Results

```{r figure6, echo=FALSE, cache=TRUE, warning=FALSE, fig.height=4, fig.width=6.5, fig.cap="Pseudo repeat sales South African art price indices (2000Q1=100)"}
index_plot <- melt(rep_indices[,-2], id="Date")  # convert to long format
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable)) 
g <- g + geom_point(size = 1) 
g <- g + geom_line()
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.title=element_blank()) + theme(legend.position="bottom")
g 
```


#Comparison and Evaluation

##Comparison of the indices

```{r figure7, echo=FALSE, cache = TRUE, warning=FALSE, fig.height=4, fig.width=6.5, fig.cap="Comparing South African art price indices (2000Q1=100)"}
all_indices <- cbind(hedonic_indices[-1],rep_indices[,c(-1,-2)])
all_indices <- rbind(c(seq(100,100, length.out = ncol(rep_indices))),all_indices)
all_indices[3,7] <- 100
all_indices <- cbind(all_indices,Median=naive_index$Index_Naive)
all_indices <- cbind(Date=naive_index$Date, all_indices)


index_plot <- melt(all_indices[,c(1,2,6,9)], id="Date")  # convert to long format
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable)) 
g <- g + geom_point(size = 1) 
g <- g + geom_line()
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.title=element_blank()) + theme(legend.position="bottom")
g
```

##Correlations

```{r table5, echo=FALSE, results='asis', warning=FALSE, message=FALSE, cache = TRUE}
temp_indices <- all_indices
colnames(temp_indices) <- c("Date","Hedonic","Adj1y","Adj2y","Roll","ps.RS(1%)","ps.RS(0.1%)","ps.RS(0)","Median")
# Check correlations (in levels and growth rates)
source("corstarsl.R")
for(i in 2:ncol(temp_indices)) {temp_indices[,i] <- as.numeric(temp_indices[,i]) }
ts.all_indices <- as.ts(temp_indices[,-1],start =c(2000,1),end=c(2015,4),frequency=4)
dl.indices <- as.data.frame(diff(log(ts.all_indices)))
xt <- xtable(corstarsl(dl.indices), caption="Correlations in DLogs")
print(xt, "latex",comment=FALSE, caption.placement = getOption("xtable.caption.placement", "top"), scalebox = 0.7)
```

##Evaluating index smoothness

```{r table6, echo=FALSE, results='asis', message=FALSE, cache = TRUE}
##Comparing index smoothness
# Check std dev or volatility en AC(1)
ac.1 <-numeric()
eval <- data.frame()
returns <- all_indices
for(i in 2:ncol(all_indices)) {
    for(j in 2:nrow(all_indices)) {
        returns[j,i] <- all_indices[j,i]/all_indices[j-1,i] - 1
    }
}
returns <- returns[-1,-1]

vol <- apply(returns,MARGIN=2, FUN=sd, na.rm=TRUE)
for(i in 1:ncol(returns)) {
    ac.1[i] <- acf(returns,na.action = na.pass, plot = FALSE, lag.max = 1)$acf[,,i][2,i]
}
eval <- cbind(vol=vol,ac.1=ac.1[1:8])
xt <- xtable(eval, caption="Smoothness Indicators")
print(xt, "latex",comment=FALSE, caption.placement = getOption("xtable.caption.placement", "top"))
```

##Compared to international art price indices

```{r figure8, echo=FALSE, cache = TRUE, warning=FALSE, fig.height=4, fig.width=6.5, fig.cap="Comparing art price indices (2000Q1=100)"}
#Compared to other art markets
assets <- read.csv("Assets.csv", header=TRUE, na.strings = "", skipNul = TRUE)
index_plot <- cbind(all_indices[,c(1,2,6)],assets[,c(7,8,9)])
index_plot <- melt(index_plot, id="Date")  # convert to long format
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable)) 
g <- g + geom_line()
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.title=element_blank()) + theme(legend.position="bottom")
g
```


# Bubbles

## Bubbles in Asset Prices

Rational bubbles: willing to pay more than fundamental value 

- expect asset price will  exceed its fundamental value in future

Gap between market fundamental and the actual price

Present value of asset:
$$P_t = F_t + B_t$$
$$F_t = E_t[\Sigma_{i=1}^n \frac{1}{1+r_f} (\gamma_{t+n})]$$ 
$$B_t = \frac{1}{1+r_f}E_t(B_{t+n})$$ 

Properties of $P_t$ are determined by those of $F_t$ and $B_t$

If bubble is present, $B_t \neq 0$, prices exhibit explosive behaviour

So look for mildly explosive behaviour in price series

## Methodology: Explosive Behaviour
Method proposed by Phillips et al (2011)

Recursive autoregressive models (log real indices):
$$\Delta y_t = \alpha_w + (\rho_w-1)y_{t-1}+\sum_{i=1}^k\phi_w^i \Delta y_{t-i} + \epsilon_t $$

Right-tailed Augmented Dickey-Fuller tests

Critical values from Monte Carlo simulations

Date stamp origination and termination


```{r bubbles, echo=FALSE, results='hide', message=FALSE, warning=FALSE, cache = TRUE}
#==============================#
# Bubbles: Explosive Behaviour
#==============================#
#Make them real
real_indices <- all_indices
for(i in 2:ncol(all_indices)) { 
    for(j in 1:64) {
        real_indices[j,i] <- all_indices[j,i]/assets$CPI[j]*100 
    }
}

#Calculate test statistics
y_indices <- log(real_indices[,-1])
bubble.nc <- list()
bubble.c <- list()
for(i in 1:ncol(y_indices)) {
    bubble1 <- numeric()
    bubble2 <- numeric()
    for(j in 12:64) {
        y <- y_indices[1:j,i]
        #toets1 <- adf.test(y, alternative = "explosive", k=4)
        #bubble1 <- rbind(bubble1,toets1$statistic)
        toets1 <- ur.df(y, type= "none", lags = 4, selectlags = c("AIC"))
        toets2 <- ur.df(y, type= "drift", lags = 4, selectlags = c("AIC"))
        #toets <- ur.df(y, type= "trend", lags = 4, selectlags = c("AIC"))
        bubble1 <- rbind(bubble1,toets1@teststat)
        bubble2 <- rbind(bubble2,toets2@teststat)
    }
    bubble.nc[[i]] <- bubble1
    bubble.c[[i]] <- bubble2
}

##--------------------------------------------------------------------------
#Calculate critical values
K1 <- numeric()
K2 <- numeric()
K3 <- numeric()
K4 <- numeric()

for(j in 12:64) {
    set.seed(123)                           #for replicability
    reps <- 2000                            #Monte Carlo replications
    burn <- 100                             #burn in periods: first generate a T+B sample
    #obs <- 62                              #To make "sure" that influence of initial values has faded
    obs <- j                                #ultimate sample size
    tstat.nc <- numeric()
    tstat.c <- numeric()
    tstat.ct <- numeric()
    tstat.lc <- numeric()
    
    for(i in 1:reps) {     
        e <- rnorm(obs+burn)
        e[1] <- 0
        Y1 <- cumsum(e)
        DY1 <- diff(Y1)
        
        y1 <- Y1[(burn+1):(obs+burn)]               #trim off burn period
        dy1 <- DY1[(burn+1):(obs+burn)]             
        ly1 <- Y1[burn:(obs+burn-1)] 
        trend <- 1:obs

        EQ1 <- lm(dy1 ~ 0 + ly1)       
        tstat.nc <- rbind(tstat.nc,summary(EQ1)$coefficients[1,3]) 
        EQ2 <- lm(dy1 ~ ly1)            
        tstat.c <- rbind(tstat.c,summary(EQ2)$coefficients[2,3])  
        EQ3 <- lm(dy1 ~ lag(y1) + trend)    
        tstat.ct <- rbind(tstat.ct,summary(EQ3)$coefficients[2,3]) 
    }                                       
    #hist(tstat.nc)
    K1 <- rbind(K1,quantile(tstat.nc, probs=c(0.9,0.95,0.99)))
    K2 <- rbind(K2,quantile(tstat.c, probs=c(0.9,0.95,0.99)))
    K3 <- rbind(K3,quantile(tstat.ct, probs= c(0.9,0.95,0.99)))
}   #Provides a vector of critical values

##---------------------------------------------------------------------------
#plot die test stats en critical values 
bubble.test1 <- numeric()
bubble.test2 <- numeric()

for(k in 1:8) { 
    bubble.test1 <- cbind(bubble.test1,bubble.nc[[k]])
    bubble.test2 <- cbind(bubble.test2,bubble.c[[k]][1:53])
}
bubble.test1 <- as.data.frame(bubble.test1)
bubble.test2 <- as.data.frame(bubble.test2)
bubble.test1 <- cbind(bubble.test1,K1)
bubble.test2 <- cbind(bubble.test2,K2)

Dates <- c("2002Q4","2003Q1","2003Q2","2003Q3","2003Q4","2004Q1","2004Q2","2004Q3","2004Q4","2005Q1","2005Q2","2005Q3","2005Q4",
           "2006Q1","2006Q2","2006Q3","2006Q4","2007Q1","2007Q2","2007Q3","2007Q4","2008Q1","2008Q2","2008Q3","2008Q4",
           "2009Q1","2009Q2","2009Q3","2009Q4","2010Q1","2010Q2","2010Q3","2010Q4","2011Q1","2011Q2","2011Q3","2011Q4",
           "2012Q1","2012Q2","2012Q3","2012Q4","2013Q1","2013Q2","2013Q3","2013Q4","2014Q1","2014Q2","2014Q3","2014Q4",
           "2015Q1","2015Q2","2015Q3","2015Q4")
bubble.test1$Date <- Dates
bubble.test2$Date <- Dates

colnames(bubble.test1)[1:8] <- c("Hedonic_Full","Adjacent_1y","Adjacent_2y","Rolling","ps.RS(1%)","ps.RS(0.1%)","ps.RS(nearest)","Median")
colnames(bubble.test2)[1:8] <- c("Hedonic_Full","Adjacent_1y","Adjacent_2y","Rolling","ps.RS(1%)","ps.RS(0.1%)","ps.RS(nearest)","Median")
```

## Results: No Drift or Trend

```{r figure10, echo=FALSE, message=FALSE, warning=FALSE, cache = TRUE, fig.height=4, fig.width=6.5, fig.cap="Full hedonic model: Test stat and critical values"}
index_plot <- bubble.test1[,c(1,5,8,10,11,12)]
index_plot <- melt(index_plot, id="Date")  # convert to long format
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable)) 
g <- g + geom_point(size = 1) 
g <- g + geom_line()
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.title=element_blank()) + theme(legend.position="bottom")
g
```


## Results: Drift

```{r figure11, echo=FALSE, message=FALSE, warning=FALSE, cache = TRUE, fig.height=4, fig.width=6.5, fig.cap="ps-RS model(0.1%): Test stat and critical values"}
index_plot <- bubble.test2[,c(1,5,8,10,11,12)]
index_plot <- melt(index_plot, id="Date")  # convert to long format
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable)) 
g <- g + geom_point(size = 1) 
g <- g + geom_line()
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.title=element_blank()) + theme(legend.position="bottom")
g
```

## Bubble Dates

```{r dates, echo=FALSE, results='hide', message=FALSE, warning=FALSE, cache = TRUE}
#report bubble period dates
datum1 <- data.frame()
datum2 <- data.frame()
datums1 <- data.frame()
datums2 <- data.frame()

for(i in 1:7) {
    for(l in 1:53) {
        if(bubble.test1[l,i]>bubble.test1$"95%"[l]) { 
            datum1[l,i] <- bubble.test1[l,"Date"]
        }
        if(bubble.test2[l,i]>bubble.test2$"95%"[l]) { 
            datum2[l,i] <- bubble.test2[l,"Date"]
        }
    }
    NonNAindex <- which(!is.na(datum1[,i]))
    firstNonNA <- min(NonNAindex)
    datums1[1,i] <- datum1[firstNonNA,i]
    if (NonNAindex[NROW(NonNAindex)-1]==(max(NonNAindex)-1)) { 
         lastNonNA <- max(NonNAindex)
    } else lastNonNA <- NonNAindex[NROW(NonNAindex)-1]
    datums1[2,i] <- datum1[lastNonNA,i]
    
    NonNAindex <- which(!is.na(datum2[,i]))
    firstNonNA <- min(NonNAindex)
    datums2[1,i] <- datum2[firstNonNA,i]
    lastNonNA <- max(NonNAindex)
    datums2[2,i] <- datum2[lastNonNA,i]
}    
    
datums <- rbind(datums1,datums2)
colnames(datums) <- colnames(bubble.test1)[1:7]
rownames(datums) <- c("None-Start","None-End","Drift-Start","Drift-End")
datums <- t(datums)
```

```{r table7, echo=FALSE, results='asis', message=FALSE, cache = TRUE}
xt <- xtable(datums, caption="Dates of explosive behaviour")
print(xt, "latex",comment=FALSE, caption.placement = getOption("xtable.caption.placement", "top"))
```

# Conclusion

## Conclusion
Sukkel sukkel...

------------------------------------------------
![alt text](Mealies.png)




