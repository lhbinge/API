---
title: "Modelling South African Art Prices"
subtitle: "An analysis of post-2000 price behaviour"
author: Laurie Binge
date: "17 November 2016"
output:
  beamer_presentation:
    includes:
      in_header: mystyle.tex
    theme: "CambridgeUS"
    colortheme: "dolphin"
    fonttheme: "structurebold" 
    toc: true
    slide_level: 2
---


#Introduction

## The South African Art Market

Surge in popularity of South African art 

Record prices at international and local auctions   

- Irma Stern's *"Arab Priest"* sold for £2.7m in 2011 by Bonhams 
- Irma Stern's *"Two Arabs"* sold for R19m in 2011 by Strauss & Co

Prompted many claims of a "bubble" in the art market   

Objectives:  

1) Construct SA art price indices over time
2) Use simple hybrid repeat sales method (robustness test)
3) Test for evidence of a bubble in SA art market prices (application)


## Arab Priest - Irma Stern
![alt text](Arab_Priest.png)

## Two Arabs - Irma Stern
![alt text](Two Arabs.jpg)


# Data

```{r cleaning, echo=FALSE, results='hide', message=FALSE, warning=FALSE, cache = TRUE}
##=====================##
## READING IN THE DATA ##
##=====================##
suppressMessages(library(zoo))
suppressMessages(library(ggplot2))
suppressMessages(library(plyr))
suppressMessages(library(dplyr))
suppressMessages(library(reshape2))
suppressMessages(library(stargazer))
suppressMessages(library(micEcon))
suppressMessages(library(quantreg))
suppressMessages(library(McSpatial))
suppressMessages(library(quantmod))
suppressMessages(library(xtable))
suppressMessages(library(scales))
suppressMessages(library(tseries))
suppressMessages(library(urca))
suppressMessages(library(mFilter))

setwd("C:\\Users\\Laurie\\OneDrive\\Documents\\BING\\Art Price Index\\R Code")
artdata <- read.csv("Auction database.csv", header=TRUE, sep=",",na.strings = "", skipNul = TRUE, 
                    colClasses=c("character","numeric","numeric","numeric","numeric","factor","factor","factor","character",
                                 "factor","factor","factor","character","factor","factor","factor","numeric","character",
                                 "numeric","numeric","numeric","numeric","numeric","numeric"))

##===================##
## CLEANING THE DATA ##
##===================##
artdata$date <- as.Date(artdata$date)
artdata$med_code <- factor(artdata$med_code, labels=c("Drawing", "Watercolour", "Oil", "Acrylic", "Print/Woodcut",
                                                      "Mixed Media","Sculpture","Photography", "Other"))
artdata$ah_code <- factor(artdata$ah_code, labels=c("5th Avenue","Ashbeys","Bernardi","Bonhams","Russell Kaplan",
                                                    "Stephan Welz","Strauss","Christies"))
artdata$timedummy <- factor(as.yearqtr(artdata$date, "%Y-%m-%d"))
artdata$lnprice <- log(artdata$price)
artdata$lnarea <- log(artdata$area)
artdata$lnarea2 <- artdata$lnarea*artdata$lnarea
#inteaction term: sculptures often only reported with 1 dimension (height)
artdata$lnsculpt_area <- ifelse(artdata$med_code=="Sculpture", artdata$lnarea, 0)
artdata$counter <- as.numeric(artdata$timedummy)

##----------------------
##Rank Artists by Volume
##----------------------
#Rank by Total Volume (all)
rankings <- count(artdata, artist)
rankings$rank_all <- dense_rank(desc(rankings$n))    #rank by density, with no gaps (ties = equal)
rankings$rank_total <- row_number(desc(rankings$n))  #equivalent to rank(ties.method = "first")
rankings$n <- NULL

artdata <- merge(artdata, rankings, by.x="artist", by.y="artist",all.x=TRUE)
```

```{r loadrep, echo=FALSE, results='hide', message=FALSE, warning=FALSE, cache = TRUE}
#------------------------------------------------------------------------------------------------------------------------------
#Load pre-calculated dataset (for speed) from API_3.R
artdata <- read.csv("artdata_lnrep.csv", header=TRUE)
artdata$med_code <- factor(artdata$med_code, labels=c("NA","Drawing", "Watercolour", "Oil", "Acrylic", "Print/Woodcut",
                                                      "Mixed Media","Sculpture","Photography", "Other"))
```

## South African Art Auction Data

Auction data from AuctionVault:

- 2000-2015
- 8 auction houses
- 52,059 sales 
- 4,503 artists
- Various characteristics for each record

Public auction prices vs. private prices   

Bought-in lots


## Total Sales by Auction House
```{r figure1, echo=FALSE, cache = TRUE, fig.height=4, fig.width=6.5, fig.cap="Turnover (sum of hammer prices) by auction house (2000-2015)"}
#Plot total sales by auction house
artplot <- aggregate(artdata$hammer_price, by=list(artdata$year,artdata$ah_code), FUN = length)
g <- ggplot(artplot, aes(x=Group.1, y=x,fill=Group.2))
g <- g + geom_bar(stat="identity")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + scale_fill_discrete(name="Auction House")
g <- g + scale_y_continuous(labels=comma)
g <- g + ylab("Total Number of Sales (Auction Lots)")
g <- g + xlab("Date")
g
```


# Methodology and Results

## Measurement Methodology

Construction of price indices for unique assets is challenging:

- Low transaction frequency
- Only a small part of the overall market is traded at any given time 
- Artworks are unique (heterogeneous) 
- Composition or quality-mix not constant over time
- Difficult to compare prices over time

Estimation methodologies:

1. Central tendency methods
2. Hedonic regressions
3. Repeat sales regressions
4. Hybrid models


##Central Tendency methods
Simple measure of central tendency price distribution (average or median)

Do not adequately control for quality-mix changes over time

Still dependent on the mix of objects that come to market 

Slight improvement by stratification (e.g. ABSA)

Estimated as a baseline:

- Median prices 
- Stratified Fisher indices (by artist and medium) 


```{r naive, echo=FALSE, results='hide', message=FALSE, warning=FALSE, cache = TRUE}
##----------------------##
##---CENTRAL TENDENCY---##
##----------------------##
naive_index <- aggregate(artdata$price, by=list(artdata$timedummy), FUN=median, na.rm=TRUE)
naive_index$index <- naive_index$x
naive_index$index <- naive_index$index/naive_index[1,2]*100
naive_index$index <- as.numeric(naive_index$index)
colnames(naive_index) <- c("Date","Median","Median_Index")

#------------------------------
#Stratify by artist and medium
#get quantity and median price per group per quarter    
strat_p <- aggregate(artdata$price, by=list(artdata$timedummy, artdata$artist, artdata$med_code), FUN=median)
strat_q <- aggregate(artdata$price, by=list(artdata$timedummy, artdata$artist, artdata$med_code), FUN=sum)
strat_q$x <- strat_q$x/strat_p$x        #the count q

chain2 <- function(strat_p, strat_q, kwartaal1,kwartaal2) {
    strat_p1 <- subset(strat_p, strat_p$Group.1==kwartaal1)
    strat_q1 <- subset(strat_q, strat_q$Group.1==kwartaal1)
    strat_p2 <- subset(strat_p, strat_p$Group.1==kwartaal2)
    strat_q2 <- subset(strat_q, strat_q$Group.1==kwartaal2)
    #get sample of median prices and quantities for specific artist for the two quarters
    strat_pc <- merge(strat_p1, strat_p2, by=c("Group.2","Group.3"))
    strat_qc <- merge(strat_q1, strat_q2, by=c("Group.2","Group.3"))
    #Laspeyres (keeps quantity weights fixed at base)
    Lasp <- sum(strat_pc$x.y*strat_qc$x.x,na.rm=TRUE)/sum(strat_pc$x.x*strat_qc$x.x,na.rm=TRUE)
    #Paasche (keeps quantity weights fixed at end)
    Paas <- sum(strat_pc$x.y*strat_qc$x.y,na.rm=TRUE)/sum(strat_pc$x.x*strat_qc$x.y,na.rm=TRUE)
    return(c(Lasp,Paas))
}

datum <- levels(artdata$timedummy)

ketting2 <- chain2(strat_p,strat_q,datum[1],datum[2])
ketting2 <- rbind(ketting2,chain2(strat_p,strat_q,datum[2],datum[3]))
for(i in 3:63) {
    ketting2 <- rbind(ketting2,chain2(strat_p,strat_q,datum[i],datum[(i+1)]))
}
ketting2 <- as.data.frame(ketting2)
ketting2$V3 <- sqrt(ketting2[,1]*ketting2[,2])  #Fisher index is the geometric mean
ketting2$V4[1] <- ketting2$V3[1]*100
for(i in 2:63) {                                #use the growth rates to generate the index
    ketting2$V4[i] <- ketting2$V4[(i-1)]*ketting2$V3[i]
}
ketting2$Date <- as.factor(datum[-1])
colnames(ketting2) <- c("Las","Paas","Fisher","Fisher_Index","Date")

naive_index <- merge(naive_index, ketting2, by.x="Date", by.y="Date",all=TRUE)
naive_index[1,4:7] <- 100
naive_indices <- naive_index[,c(1,3,7)]
```

##Central Tendency Indices
```{r figure5, echo=FALSE, cache = TRUE, fig.height=4, fig.width=6.5, fig.cap="Central tendency South African art price indices (2000Q1=100)"}
index_plot <- naive_indices
index_plot$Date <- as.Date(as.yearqtr(index_plot$Date, format = "%Y Q%q"))
index_plot <- melt(index_plot, id="Date")  # convert to long format
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable)) 
g <- g + geom_point(size = 1) 
g <- g + geom_line()
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.position="bottom") + theme(legend.title=element_blank())
g <- g + scale_x_date(labels = date_format("%Y"),breaks = date_breaks("year"))
g 
```

##Hedonic regression methodology
Prices modelled as a function of asset attributes:
$$\ln P_{it} = \sum_{t=1}^T \delta_t D_{it} + \sum_{j=1}^J \beta_{jt} X_{jit} + \sum_{k=1}^K \gamma_{kt} Z_{kit} + \epsilon_{it}$$

Control for quality by attributing implicit prices to characteristics

Strip observable characteristics to obtain "standard asset" 

Time dummies provide "pure price effect"

Potential omitted variable bias


##Artwork Attributes
- Size
- Auction houses
- Mediums
- Authenticity dummies
- Number of works in the lot
- Date dummies
- Artist
$$\text{Artist reputation index} = \frac{\prod_{i=1}^n(P_{i,y})^\frac{1}{n}/\prod_{i=1}^m(P_{i,0})^\frac{1}{m}}{\exp \left[\sum_{j=1}^z\beta_j(\sum_{i=0}^n \frac{X_{ij,y}}{n}- \sum_{i=1}^m \frac{X_{ij,0}}{m})\right]} $$


## Size or surface area by medium
```{r figure3, echo=FALSE, warning=FALSE, cache = TRUE, fig.height=4, fig.width=7.5, fig.cap="Relationship between prices and artwork sizes, by medium"}
#Plot surface area and prices by medium
library(png)
library(grid)
grid.raster(readPNG("area2.png"))
```


## Reputation
```{r figure4, echo=FALSE, warning=FALSE, cache = TRUE, fig.height=4, fig.width=7.5, fig.cap="Relationship between prices and reputation index"}
#Plot artist reputation index and prices
library(png)
library(grid)
grid.raster(readPNG("reputation.png"))
```

## Adjacent Periods
```{r hedonicrep, echo=FALSE, results='hide', message=FALSE, warning=FALSE, cache = TRUE}
#-------------------
# FULL SAMPLE MODEL
#-------------------
full_model <- function(artdata, list_expl_vars=c("lnarea","ah_code","med_code","lnsculpt_area","dum_signed", "dum_dated",  
                                                 "nr_works","artist","timedummy")) {
    modeldata <- artdata
    expl_vars <- as.formula(paste("lnprice~",paste(list_expl_vars,collapse="+")))
    model_all <- lm(expl_vars, data=modeldata)
    time_results <- summary(model_all)$coefficients[grepl("time", rownames(summary(model_all)$coefficients)),1]
    time_results <- as.data.frame(time_results)
    time_results$index_all <- exp(time_results$time_results)*100
    return(time_results)
}

#-----------------------------
# OVERLAPPING PERIODS (1-year)
#-----------------------------
overlap1y_model <- function(artdata, list_expl_vars=c("lnarea","ah_code","med_code","lnsculpt_area","dum_signed", "dum_dated",  
                                                      "nr_works","artist","timedummy")) {
    expl_vars <- as.formula(paste("lnprice~",paste(list_expl_vars,collapse="+")))
    res_list <- list()
    for(i in 1:16) {
        modeldata <- artdata
        modeldata <- subset(modeldata, modeldata$counter>(i*4-5)& modeldata$counter<(i*4+1))
        model <- lm(expl_vars, data=modeldata)  
        res_list[[i]] <- summary(model)$coefficients[grepl("time", rownames(summary(model)$coefficients)),1]
    }
    #Merge all results
    overlap <- rep_results
    overlap$time_results <- NULL
    overlap <- merge(overlap, res_list[[1]], by="row.names", all=TRUE)
    overlap[,3] <- exp(overlap[,3])*100
    for(i in 2:16) {
        overlap <- merge(overlap, res_list[[i]], by.x = "Row.names", by.y = "row.names", all=TRUE)
        overlap[,(i+2)] <- exp(overlap[i+2])*100
    } 
    #Calculate index
    overlap$ind <- overlap[,3]
    overlap[2,19] <- overlap[3,19]*overlap[2,2]/overlap[3,2]   #Interpolate
    overlap$teller <- c(3,3,3,4,4,4,4,5,5,5,5,6,6,6,6,7,7,7,7,8,8,8,8,9,9,9,9,10,10,10,10,11,11,11,11,12,12,12,12,
                        13,13,13,13,14,14,14,14,15,15,15,15,16,16,16,16,17,17,17,17,18,18,18,18)
    for(i in 3:62) {
        j <- overlap[(i+1),20]
        if(is.na(overlap[i,j])) {
            overlap[(i+1),19] <- overlap[i,19]*overlap[(i+1),j]/100
        } else { 
            overlap[(i+1),19] <- overlap[i,19]*overlap[(i+1),j]/overlap[i,j] 
        }   
    }
    colnames(overlap) <- c("Date","Index_Full","Index_m1","Index_m2","Index_m3","Index_m4","Index_m5","Index_m6",
                           "Index_m7","Index_m8","Index_m9","Index_m10","Index_m11","Index_m12","Index_m13",
                           "Index_m14","Index_m15","Index_m16","Index_Adjacent1y","teller")
    overlap$Date <- factor(levels(artdata$timedummy)[-1])
    return(overlap)
}

#-----------------------------
# OVERLAPPING PERIODS (2-year)
#-----------------------------
overlap2y_model <- function(artdata, list_expl_vars=c("lnarea","ah_code","med_code","lnsculpt_area","dum_signed", "dum_dated",  
                                                      "nr_works","artist","timedummy")) {
    expl_vars <- as.formula(paste("lnprice~",paste(list_expl_vars,collapse="+")))
    res_list <- list()
    for(i in 1:8) {
        modeldata <- artdata
        modeldata <- subset(modeldata, modeldata$counter>(i*8-9)& modeldata$counter<(i*8+1))
        model <- lm(expl_vars, data=modeldata)  
        res_list[[i]] <- summary(model)$coefficients[grepl("time", rownames(summary(model)$coefficients)),1]
    }
    #Merge all results
    overlap2 <- rep_results
    overlap2$time_results <- NULL
    overlap2 <- merge(overlap2, res_list[[1]], by="row.names", all=TRUE)
    overlap2[,3] <- exp(overlap2[,3])*100
    for(i in 2:8) {
        overlap2 <- merge(overlap2, res_list[[i]], by.x = "Row.names", by.y = "row.names", all=TRUE)
        overlap2[,(i+2)] <- exp(overlap2[i+2])*100
    } 
    #Calculate index
    overlap2$ind <- overlap2[,3]
    overlap2[2,11] <- overlap2[3,11]*overlap2[2,2]/overlap2[3,2]   #Interpolate
    overlap2$teller <- c(3,3,3,3,3,3,3,4,4,4,4,4,4,4,4,5,5,5,5,5,5,5,5,6,6,6,6,6,6,6,6,
                         7,7,7,7,7,7,7,7,8,8,8,8,8,8,8,8,9,9,9,9,9,9,9,9,10,10,10,10,10,10,10,10)
    for(i in 7:62) {
        j <- overlap2[(i+1),12]
        if(is.na(overlap2[i,j])) {
            overlap2[(i+1),11] <- overlap2[i,11]*overlap2[(i+1),j]/100
        } else { 
            overlap2[(i+1),11] <- overlap2[i,11]*overlap2[(i+1),j]/overlap2[i,j] 
        }   
    }
    colnames(overlap2) <- c("Date","Index_Full","Index_m1","Index_m2","Index_m3","Index_m4","Index_m5",
                            "Index_m6","Index_m7","Index_m8","Index_Adj2y","teller")
    overlap2$Date <- factor(levels(artdata$timedummy)[-1])
    return(overlap2)
}

#----------------------
#ROLLING 5-YEAR WINDOWS
#----------------------
rolling_model <- function(artdata, list_expl_vars=c("lnarea","ah_code","med_code","lnsculpt_area","dum_signed", "dum_dated",  
                                                    "nr_works","artist","timedummy")) {
    expl_vars <- as.formula(paste("lnprice~",paste(list_expl_vars,collapse="+")))
    res_list <- list()
    for(i in 1:12) {
        modeldata <- artdata
        modeldata <- subset(modeldata, modeldata$counter>(i*4-4)&modeldata$counter<(i*4+17))
        model <- lm(expl_vars, data=modeldata)  
        summary(model)
        res_list[[i]] <- summary(model)$coefficients[grepl("time", rownames(summary(model)$coefficients)),1]
    }
    
    #Merge all results
    rolling <- rep_results
    rolling$time_results <- NULL
    rolling <- merge(rolling, res_list[[1]], by="row.names", all=TRUE)
    rolling[,3] <- exp(rolling[,3])*100
    for(i in 2:12) {
        rolling <- merge(rolling, res_list[[i]], by.x = "Row.names", by.y = "row.names", all=TRUE)
        rolling[,(i+2)] <- exp(rolling[i+2])*100
    }    
    
    #Calculate index
    rolling$ind <- rolling[,3]
    rolling[2,15] <- rolling[3,15]*rolling[2,2]/rolling[3,2]  #interpolate
    rolling$teller <- c(3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,3,4,4,4,4,5,5,5,5,6,6,6,6,7,7,7,7,8,8,8,8,9,9,9,9,
                        10,10,10,10,11,11,11,11,12,12,12,12,13,13,13,13,14,14,14,14)
    for(i in 19:62) {  #chaining
        j <- rolling[(i+1),16]
        rolling[(i+1),15] <- rolling[i,15]*rolling[(i+1),j]/rolling[i,j]
    }
    
    colnames(rolling) <- c("Date","Index_Full","Index_m1","Index_m2","Index_m3","Index_m4","Index_m5","Index_m6",
                           "Index_m7","Index_m8","Index_m9","Index_m10","Index_m11","Index_m12","Index_Rolling","teller")
    rolling$Date <- factor(levels(artdata$timedummy)[-1])
    return(rolling)
}

#========================================================================================
list_expl_vars <- c("lnarea","ah_code","med_code","lnsculpt_area","dum_signed","dum_dated",  
                    "nr_works","lnrep","timedummy")

rep_results <- full_model(artdata,list_expl_vars)
suppressMessages(rep_overlap1 <- overlap1y_model(artdata,list_expl_vars))
suppressMessages(rep_overlap2 <- overlap2y_model(artdata,list_expl_vars))
suppressMessages(rep_rolling <- rolling_model(artdata,list_expl_vars))

hedonic_indices <- rep_overlap1[,c(1,2)]
colnames(hedonic_indices) <- c("Date","Hedonic_full")
hedonic_indices <- cbind(hedonic_indices,Adjacent_1y=rep_overlap1[,19])
hedonic_indices <- cbind(hedonic_indices,Adjacent_2y=rep_overlap2[,11])
hedonic_indices <- cbind(hedonic_indices,Rolling=rep_rolling[,15])
hedonic_indices <- cbind(Date=factor(levels(artdata$timedummy)),
                         rbind(c(seq(100,100, length.out=4)),hedonic_indices[,-1]))
```


```{r figure6, echo=FALSE, warning=FALSE, cache = TRUE, fig.height=3.5, fig.width=7.5, fig.cap="Chain-linked two-year adjacent period art price index"}
index_plot <- melt(rep_overlap2[,c(-2,-12)], id="Date")  # convert to long format
index_plot$Date <- as.Date(as.yearqtr(index_plot$Date, format = "%Y Q%q"))
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable)) 
g <- g + geom_point(size = 1) 
g <- g + geom_line()
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.title=element_blank())
g <- g + scale_x_date(labels = date_format("%Y"),breaks = date_breaks("year"))
g 
```

## Hedonic Indices

```{r figure7, echo=FALSE, cache = TRUE, fig.height=4, fig.width=7, fig.cap="Hedonic South African art price indices (2000Q1=100)"}
index_plot <- melt(hedonic_indices, id="Date")  # convert to long format
index_plot$Date <- as.Date(as.yearqtr(index_plot$Date, format = "%Y Q%q"))
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable)) 
g <- g + geom_point(size = 1) 
g <- g + geom_line()
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.position="bottom") + theme(legend.title=element_blank())
g <- g + scale_x_date(labels = date_format("%Y"),breaks = date_breaks("year"))
g
```

##Repeat Sales Regression Method
Track repeated sale of a specific asset over time (e.g. Case-Shiller)

Aggregate sales pairs and estimate average return in each period
$$\ln\frac{P_{t+1}}{P_t} =\sum_{i=1}^t\gamma_id_{i}+\epsilon_{i}$$

Controls for all attributes (if they are constant) 

Wasteful of data (single-sale data discarded)

- limited number of repeat sales pairs (515) 

Potential sample selection bias

- e.g. low-quality houses often sell more frequently


## Repeat Sales Index
```{r repeatsales, echo=FALSE, results='hide', message=FALSE, warning=FALSE, cache = TRUE}
##=====================##
## REPEAT SALES METHOD ##
##=====================##
#check for duplicates (how many)
sum(duplicated(artdata[,c("artist","title","med_code","area","dum_signed","dum_dated","nr_works")]))
allDup <- function(value) {  #identify duplicated values
    duplicated(value) | duplicated(value, fromLast = TRUE)
}
rsartdata <- artdata[allDup(artdata[,c("artist","title","med_code","area","dum_signed","dum_dated","nr_works")]),]
rsartdata <- transform(rsartdata, id = as.numeric(interaction(artist,factor(title),med_code,factor(area),factor(dum_signed),
                                                              factor(dum_dated), factor(nr_works),drop=TRUE)))

repdata <- repsaledata(rsartdata$lnprice,rsartdata$counter,rsartdata$id)  #transform the data to sales pairs
repdata <- repdata[complete.cases(repdata),]
repeatsales <- repsale(repdata$price0,repdata$time0,repdata$price1,repdata$time1,mergefirst=1,
                       graph=FALSE)   #generate the repeat sales index
RS_index <- exp(as.data.frame(repeatsales$pindex))*100   
RS_index$Date <- levels(rsartdata$timedummy)[c(-1:-3,-11,-15,-19,-29)] #missing values

RS_index <- merge(RS_index, naive_indices, by="Date", all=TRUE)[,1:2]
colnames(RS_index) <- c("Date","Repeat Sales_Index")            
```

```{r figure8, echo=FALSE, warning=FALSE, cache = TRUE, fig.height=4, fig.width=7, fig.cap="Repeat sales index of South African art prices (2000Q4=100)"}
index_plot <- melt(RS_index, id="Date")  # convert to long format
index_plot$Date <- as.Date(as.yearqtr(index_plot$Date, format = "%Y Q%q"))
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable)) 
g <- g + geom_point(size = 1) 
g <- g + geom_line()
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.title=element_blank()) + theme(legend.position="bottom")
g <- g + scale_x_date(labels = date_format("%Y"),breaks = date_breaks("year"))
g
```

##Hybrid Models: The Pseudo Repeat Sales Method
Limited repeat sales or perfect matches (*Wheat Field with Crows*)

Match similar assets over time (*Sunflowers*)

Address scarcity of repeat sales by creating pseudo pairs

Can be derived from the first differenced hedonic model:
$$\ln P_{it} - \ln P_{hs} = \sum_{j=1}^J \beta_j (X_{itj} - X_{hsj}) + \sum_{t=0}^T \delta_t G_{it} + \epsilon_{iths}$$

Control for possible omitted variables by taking first differences

- interaction and squared terms
- finer mediums & materials (e.g. linocuts and canvas)

1) Match by all attributes, except title (6,642 sales pairs)
2) All attributes, except title & authenticity dummies (7,965)

```{r psRSsample, echo=FALSE, results='hide', message=FALSE, warning=FALSE, cache = TRUE}
##------------------------------------------------------------------
##--------------- Pseudo Repeat Sales ------------------------------
##------------------------------------------------------------------
#do the same but expand it to not match by title - i.e. all other attributes are the same
#check for duplicates (how many)
sum(duplicated(artdata[,c("artist","med_code","area","dum_signed","dum_dated","nr_works")]))
rsartdata1 <- artdata[allDup(artdata[,c("artist","med_code","area","dum_signed","dum_dated","nr_works")]),]
rsartdata1 <- transform(rsartdata1, id = as.numeric(interaction(artist,med_code,factor(area),factor(dum_signed),
                                                                factor(dum_dated),factor(nr_works), drop=TRUE)))

repdata1 <- cbind(repsaledata(rsartdata1$lnprice,rsartdata1$counter,rsartdata1$id),
                  repsaledata(rsartdata1$ah_code,rsartdata1$counter,rsartdata1$id)[,4:5]) #transform the data to sales pairs
repdata1 <- repdata1[complete.cases(repdata1),]
colnames(repdata1) <- c("id","time0","time1","price0","price1","ah_code0","ah_code1")

dy <- repdata1$price1 - repdata1$price0
ah0 <- model.matrix(~repdata1$ah_code0)
ah1 <- model.matrix(~repdata1$ah_code1)
dah <- ah1 - ah0

timevar <- levels(factor(c(repdata1$time0, repdata1$time1)))
nt = length(timevar)
n = length(dy)
xmat <- array(0, dim = c(n, nt - 1))
for (j in seq(1 + 1, nt)) {
    xmat[,j-1] <- ifelse(repdata1$time1 == timevar[j], 1, xmat[,j-1])
    xmat[,j-1] <- ifelse(repdata1$time0 == timevar[j],-1, xmat[,j-1])
}
colnames(xmat) <- paste("Time", seq(1 + 1, nt))

ps.RS <- lm(dy ~ dah + xmat + 0)
RS_index1 <- summary(ps.RS)$coefficients[grepl("Time", rownames(summary(ps.RS)$coefficients)),1]
RS_index1 <- as.data.frame(RS_index1)
RS_index1$index <- exp(RS_index1$RS_index1)*100
RS_index1$Date <- levels(rsartdata1$timedummy)[-1]
RS_index1 <- RS_index1[,c(2,3)]

##=====================##
#do the same but expand it to not match by title or authenticity dummies
#check for duplicates (how many)
sum(duplicated(artdata[,c("artist","med_code","area","nr_works")]))
rsartdata2 <- artdata[allDup(artdata[,c("artist","med_code","area","nr_works")]),]
rsartdata2 <- transform(rsartdata2, id = as.numeric(interaction(artist,med_code,factor(area),factor(nr_works), drop=TRUE)))

repdata2 <- cbind(repsaledata(rsartdata2$lnprice,rsartdata2$counter,rsartdata2$id),
                  repsaledata(rsartdata2$ah_code,rsartdata2$counter,rsartdata2$id)[,4:5],
                  repsaledata(rsartdata2$dum_signed,rsartdata2$counter,rsartdata2$id)[,4:5],
                  repsaledata(rsartdata2$dum_dated,rsartdata2$counter,rsartdata2$id)[,4:5])
repdata2 <- repdata2[complete.cases(repdata2),]
colnames(repdata2) <- c("id","time0","time1","price0","price1","ah_code0","ah_code1","sign0","sign1","date0","date1")

dy <- repdata2$price1 - repdata2$price0
dsign <- repdata2$sign1 - repdata2$sign0
ddate <- repdata2$date1 - repdata2$date0
ah0 <- model.matrix(~repdata2$ah_code0)
ah1 <- model.matrix(~repdata2$ah_code1)
dah <- ah1 - ah0

timevar <- levels(factor(c(repdata2$time0, repdata2$time1)))
nt = length(timevar)
n = length(dy)
xmat <- array(0, dim = c(n, nt - 1))
for (j in seq(1 + 1, nt)) {
    xmat[,j-1] <- ifelse(repdata2$time1 == timevar[j], 1, xmat[,j-1])
    xmat[,j-1] <- ifelse(repdata2$time0 == timevar[j],-1, xmat[,j-1])
}
colnames(xmat) <- paste("Time", seq(1 + 1, nt))

ps.RS <- lm(dy ~ dah + dsign + ddate + xmat + 0)
RS_index2 <- summary(ps.RS)$coefficients[grepl("Time", rownames(summary(ps.RS)$coefficients)),1]
RS_index2 <- as.data.frame(RS_index2)
RS_index2$index <- exp(RS_index2$RS_index2)*100
RS_index2$Date <- levels(rsartdata2$timedummy)[-1]
RS_index2 <- RS_index2[,c(2,3)]

#------------------------------------------------------------------------
RS_indices <- merge(RS_index, RS_index1, by="Date", all=TRUE)
RS_indices <- merge(RS_indices, RS_index2, by="Date", all=TRUE)
RS_indices[1,2:4] <- 100
colnames(RS_indices) <- c("Date","Repeat Sales","pseudo-RS1","pseudo-RS2")          
```

##Pseudo Repeat Sales Indices

```{r figure9, echo=FALSE, cache=TRUE, warning=FALSE, fig.height=4, fig.width=7.5, fig.cap="Pseudo repeat sales South African art price indices (2000Q1=100)"}
index_plot <- melt(RS_indices[,-2], id="Date")  # convert to long format
index_plot$Date <- as.Date(as.yearqtr(index_plot$Date, format = "%Y Q%q"))
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable)) 
g <- g + geom_point(size = 1) 
g <- g + geom_line()
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.title=element_blank()) + theme(legend.position="bottom")
g <- g + scale_x_date(labels = date_format("%Y"),breaks = date_breaks("year"))
g
```

#Comparison and Evaluation

##Comparison of the indices

```{r figure10, echo=FALSE, cache = TRUE, warning=FALSE, fig.height=4, fig.width=7.5, fig.cap="Comparing South African art price indices (2000Q1=100)"}
all_indices <- cbind(naive_indices,hedonic_indices[-1],RS_indices[-1])
all_indices[is.na(all_indices)]<- 100
index_plot <- melt(all_indices[,c(1,2,6,10)], id="Date")  # convert to long format
index_plot$Date <- as.Date(as.yearqtr(index_plot$Date, format = "%Y Q%q"))
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable)) 
g <- g + geom_point(size = 1) 
g <- g + geom_line()
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.title=element_blank()) + theme(legend.position="bottom")
g <- g + scale_x_date(labels = date_format("%Y"),breaks = date_breaks("year"))
g
```


##Evaluating index smoothness

```{r table3, echo=FALSE, results='asis', warning=FALSE, message=FALSE, cache = TRUE}
##Comparing index smoothness
# Check std dev or volatility en AC(1)
ac.1 <- numeric()
eval <- data.frame()
HPdev <- numeric()
smoothness <- numeric()

vol <- apply(returns,MARGIN=2, FUN=sd, na.rm=TRUE)
for(i in 1:ncol(returns)) {
    ac.1[i] <- acf(returns,na.action = na.pass, plot = FALSE, lag.max = 1)$acf[,,i][2,i]
}

hp <- temp_indices
for(i in 2:10) {
    hp[,i] <- hpfilter(temp_indices[,i],freq = 1600)[2]
}
ts.hp <- as.ts(hp[,-1],start =c(2000,1),end=c(2015,4),frequency=4)
hpreturns <- as.data.frame(diff(log(ts.hp)))
for(i in 1:ncol(returns)) {
    HPdev[i] <- sum((hpreturns[,i] - returns[,i])^2)
}

#spectral density
smooth <- function (datavec,k,l) {     # calculates smoothness coefficient for 'datavec' with 
    # 'k' specifies the width of the Daniell window which smooths the raw periodogram 
    ## Step 1: Calculate and record power spectral density using 'speccalcs'
    speccalcs <- spec.pgram(datavec,spans=c(k,l),demean=TRUE,plot=FALSE)
    spectra <- speccalcs$spec
    
    ## Step 2 Take natural logs of power spectral frequencies
    logspec <- log(spectra)
    n <- length(logspec)
    m <- n/2
    
    p1 <- mean(logspec[1:m])
    p2 <- mean(logspec[(m+1):n])
    smcoef <- p1-p2
    smcoefvar <- (pi^2)/6*((1/m)+(1/(n-m)))
    smcoefse <- sqrt(smcoefvar)
    #list(smcoef,smcoefse)
    return(smcoef)
}
for(i in 1:10) { smoothness[i] <- smooth(all_indices[,i],3,3) }

eval <- cbind(Vol=vol,AC.1=ac.1[1:9],HPDeviation=HPdev,Smoothness=smoothness[-1])
xt <- xtable(eval, caption="Smoothness Indicators", digits=c(0,3,3,2,2))
print(xt, "latex",comment=FALSE, caption.placement = getOption("xtable.caption.placement", "top"), scalebox = 0.9) 
```

##Compared to international art price indices

```{r figure11, echo=FALSE, cache = TRUE, warning=FALSE, fig.height=4, fig.width=7.5, fig.cap="Comparing art price indices (2000Q1=100)"}
##Compared to other art markets
assets <- read.csv("Assets.csv", header=TRUE, na.strings = "", skipNul = TRUE)
index_plot <- cbind(all_indices[,c(1,6,10)],assets[,c(6,7,8)])
index_plot <- melt(index_plot, id="Date")  # convert to long format
index_plot$Date <- as.Date(as.yearqtr(index_plot$Date, format = "%Y Q%q"))
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable)) 
g <- g + geom_line()
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.title=element_blank()) + theme(legend.position="bottom")
g <- g + scale_x_date(labels = date_format("%Y"),breaks = date_breaks("year"))
g
```

##Compared to other local assets

```{r figure12, echo=FALSE, cache = TRUE, warning=FALSE, fig.height=4, fig.width=7.5, fig.cap="Comparing South African asset price indices (2000Q1=100)"}
##Compared to other assets
index_plot <- cbind(all_indices[,c(1,6,10)],assets[,c(2,3,4)])
index_plot <- melt(index_plot, id="Date")  # convert to long format
index_plot$Date <- as.Date(as.yearqtr(index_plot$Date, format = "%Y Q%q"))
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable)) 
g <- g + geom_line()
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.title=element_blank()) + theme(legend.position="bottom")
g <- g + scale_x_date(labels = date_format("%Y"),breaks = date_breaks("year"))
g 
```

# Bubbles

## Bubbles in Asset Prices

Rational bubbles: willing to pay more than fundamental value 

- expect asset price will exceed its fundamental value in future

Gap between fundamental price and market price

- difficult to determine fundamental value of art

If bubble is present - prices exhibit explosive behaviour

So look for mildly explosive behaviour in price series

## Methodology: Explosive Behaviour
Recursive autoregressive models (log real indices):
$$\Delta y_t = \alpha_w + (\rho_w-1)y_{t-1}+\sum_{i=1}^k\phi_w^i \Delta y_{t-i} + \epsilon_t $$

Right-tailed Augmented Dickey-Fuller tests

Critical values from Monte Carlo simulations

Date stamp origination and termination


```{r bubbles, echo=FALSE, results='hide', message=FALSE, warning=FALSE, cache = TRUE}
#==============================#
# Bubbles: Explosive Behaviour
#==============================#
#Make them real
real_indices <- all_indices
for(i in 2:ncol(all_indices)) { 
    for(j in 1:64) {
        real_indices[j,i] <- all_indices[j,i]/assets$CPI[j]*100 
    }
}

#Calculate test statistics
y_indices <- log(real_indices[,-1])
bubble.nc <- list()
bubble.c <- list()
for(i in 1:ncol(y_indices)) {
    bubble1 <- numeric()
    bubble2 <- numeric()
    for(j in 12:64) {
        y <- y_indices[1:j,i]
        toets1 <- ur.df(y, type= "none", lags = 4, selectlags = c("AIC"))
        toets2 <- ur.df(y, type= "drift", lags = 4, selectlags = c("AIC"))
        bubble1 <- rbind(bubble1,toets1@teststat)
        bubble2 <- rbind(bubble2,toets2@teststat)
    }
    bubble.nc[[i]] <- bubble1
    bubble.c[[i]] <- bubble2
}

##--------------------------------------------------------------------------
#Calculate critical values
K1 <- numeric()
K2 <- numeric()
K3 <- numeric()
K4 <- numeric()

for(j in 12:64) {
    set.seed(123)                           #for replicability
    reps <- 2000                            #Monte Carlo replications
    burn <- 100                             #burn in periods: first generate a T+B sample
    #obs <- 62                              #To make "sure" that influence of initial values has faded
    obs <- j                                #ultimate sample size
    tstat.nc <- numeric()
    tstat.c <- numeric()
    tstat.ct <- numeric()
    tstat.lc <- numeric()
    
    for(i in 1:reps) {     
        e <- rnorm(obs+burn)
        e[1] <- 0
        Y1 <- cumsum(e)
        DY1 <- diff(Y1)
        
        y1 <- Y1[(burn+1):(obs+burn)]               #trim off burn period
        dy1 <- DY1[(burn+1):(obs+burn)]             
        ly1 <- Y1[burn:(obs+burn-1)] 
        trend <- 1:obs
        
        EQ1 <- lm(dy1 ~ 0 + ly1)       
        tstat.nc <- rbind(tstat.nc,summary(EQ1)$coefficients[1,3]) 
        EQ2 <- lm(dy1 ~ ly1)            
        tstat.c <- rbind(tstat.c,summary(EQ2)$coefficients[2,3])  
    }                                       
    #hist(tstat.nc)
    K1 <- rbind(K1,quantile(tstat.nc, probs=c(0.9,0.95,0.99)))
    K2 <- rbind(K2,quantile(tstat.c, probs=c(0.9,0.95,0.99)))
}   #Provides a vector of critical values

bubble.test1 <- numeric()
bubble.test2 <- numeric()

for(k in 1:9) { 
    bubble.test1 <- cbind(bubble.test1,bubble.nc[[k]])
    bubble.test2 <- cbind(bubble.test2,bubble.c[[k]][1:53])
}
bubble.test1 <- as.data.frame(bubble.test1)
bubble.test2 <- as.data.frame(bubble.test2)
bubble.test1 <- cbind(bubble.test1,K1)
bubble.test2 <- cbind(bubble.test2,K2)

Dates <- levels(artdata$timedummy)[-1:-11]
bubble.test1$Date <- Dates
bubble.test2$Date <- Dates

colnames(bubble.test1)[1:9] <- colnames(all_indices[-1])
colnames(bubble.test2)[1:9] <- colnames(all_indices[-1])
```

## Results: No Drift or Trend

```{r figure13, echo=FALSE, message=FALSE, warning=FALSE, cache = TRUE, fig.height=4, fig.width=7.5, fig.cap="Test statistics and critical values for models without drift"}
index_plot <- bubble.test1[,c(1,4,9,11,12,13)]
index_plot <- melt(index_plot, id="Date")  # convert to long format
index_plot$Date <- as.Date(as.yearqtr(index_plot$Date, format = "%Y Q%q"))
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable)) 
g <- g + geom_point(size = 1) 
g <- g + geom_line(aes(linetype=variable))
g <- g + scale_linetype_manual(values = c(1,1,1,4,4))
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.title=element_blank()) + theme(legend.position="bottom")
g <- g + scale_x_date(labels = date_format("%Y"),breaks = date_breaks("year"))
g
```


## Results: Drift

```{r figure14, echo=FALSE, message=FALSE, warning=FALSE, cache = TRUE, fig.height=4, fig.width=7.5, fig.cap="Test statistics and critical values for models with drift"}
index_plot <- bubble.test2[,c(1,4,9,11,12,13)]
index_plot <- melt(index_plot, id="Date")  # convert to long format
index_plot$Date <- as.Date(as.yearqtr(index_plot$Date, format = "%Y Q%q"))
g <- ggplot(data=index_plot,aes(x=Date, y=value, group=variable, colour=variable)) 
g <- g + geom_point(size = 1) 
g <- g + geom_line(aes(linetype=variable))
g <- g + scale_linetype_manual(values = c(1,1,1,4,4))
g <- g + ylab("Index")
g <- g + xlab("")
g <- g + theme(axis.text.x=element_text(angle=90,hjust=1,vjust=0.5))
g <- g + theme(legend.title=element_blank()) + theme(legend.position="bottom")
g <- g + scale_x_date(labels = date_format("%Y"),breaks = date_breaks("year"))
g
```

## Bubble Dates

```{r dates, echo=FALSE, results='hide', message=FALSE, warning=FALSE, cache = TRUE}
#report  bubble period dates
datum1 <- data.frame()
datum2 <- data.frame()
datums1 <- data.frame()
datums2 <- data.frame()

bubble.test1 <- bubble.test1[,c(-1,-7)]
bubble.test2 <- bubble.test2[,c(-1,-7)]

for(i in 1:7) {
    for(l in 1:53) {
        if(bubble.test1[l,i]>bubble.test1$"95%"[l]) { 
            datum1[l,i] <- bubble.test1[l,"Date"]
        }
        if(bubble.test2[l,i]>bubble.test2$"95%"[l]) { 
            datum2[l,i] <- bubble.test2[l,"Date"]
        }
    }
    NonNAindex <- which(!is.na(datum1[,i]))
    firstNonNA <- min(NonNAindex)
    datums1[1,i] <- datum1[firstNonNA,i]
    if (NonNAindex[NROW(NonNAindex)-1]==(max(NonNAindex)-1)) { 
        lastNonNA <- max(NonNAindex)
    } else lastNonNA <- NonNAindex[NROW(NonNAindex)-1]
    datums1[2,i] <- datum1[lastNonNA,i]
    
    NonNAindex <- which(!is.na(datum2[,i]))
    firstNonNA <- min(NonNAindex)
    datums2[1,i] <- datum2[firstNonNA,i]
    lastNonNA <- max(NonNAindex)
    datums2[2,i] <- datum2[lastNonNA,i]
}    

datums <- rbind(datums1,datums2)
colnames(datums) <- colnames(bubble.test1)[1:7]
rownames(datums) <- c("None-Start","None-End","Drift-Start","Drift-End")
datums <- t(datums)
```

```{r table5, echo=FALSE, results='asis', message=FALSE, cache = TRUE}
xt <- xtable(datums, caption="Dates of explosive behaviour")
print(xt, "latex",comment=FALSE, caption.placement = getOption("xtable.caption.placement", "top"))
```

# Conclusion

## Conclusion

Regression-based indices:

- Differ from  central tendency measures (better i.t.o. smoothness)
- Relatively similar and consistent general cyclical trends

Potential bubble in run-up to financial crisis (2006-2008):

- High transaction costs and no short selling
- Self-fulfilling prophecy and exogenous shock
- Spillovers from other markets through wealth effect

Potential further research: 

- Risk-return profile and optimal asset allocation
- Masterpiece effect
- Potential drivers of art prices 

Suggestions and Advice?

------------------------------------------------
![alt text](Women.jpg)




