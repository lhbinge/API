tsdiag(arma11)
res11<-residuals(arma11)
Box.test(res11,lag=20,type="Ljung-Box")
shapiro.test(res11)
##Using auto.arima()
auto.arima(y,max.p=3,max.q=3,start.p=1,start.q=1,ic="aic")
##Forecasts
arma11.pred <- predict(arma11,n.ahead=10)
predict <- ts(c(rep(NA,length(y)-1),y[length(y)], arma11.pred$pred),start=1909,frequency=1)
upper <- ts(c(rep(NA,length(y)-1),y[length(y)], arma11.pred$pred+2*arma11.pred$se),start=1909,frequency=1)
lower <- ts(c(rep(NA,length(y)-1),y[length(y)], arma11.pred$pred-2*arma11.pred$se),start=1909,frequency=1)
observed <- ts(c(y,rep(NA,10)),start=1909,frequency=1)
##Plot of actual and forecasted values
plot(observed,type="l",ylab="Actual and predicted values",xlab="")
lines(predict,col="blue",lty=2)
lines(lower,col="red",lty=5)
lines(upper,col="red",lty=5)
abline(v=1988,col="gray",lty=3)
#Alternatively
plot(forecast(arma11))
##Simulate VAR(2)-data1
#install.packages("dse")
#library(vars)
##Setting the lag-polynomial A(L)
Apoly<-array(c(1.0,-0.5,0.3, 0,0.2,0.1,
0,-0.2,0.7, 1,0.5,-0.3),c(3,2,2))
##Setting Covariance to identity-matrix
B<-diag(2)
##Setting constant term to 5 and 10
TRD<-c(5,10)
##Generating the VAR(2) model
var2<-ARMA(A=Apoly,B=B,TREND=TRD)
##Simulating 500 observations
varsim<-simulate(var2,sampleT=500,noise=list(w=matrix(rnorm(1000),
nrow=500,ncol=2)),rng=list(seed=c(123456)))
##Obtaining the generated series
vardat<-matrix(varsim$output,nrow=500,ncol=2)
colnames(vardat)<-c("y1","y2")
##Plotting the series
plot.ts(vardat,main="",xlab="")
##Determining an appropriate lag-order
infocrit<-VARselect(vardat,lag.max=3,type="const")
##Estimating the model
varsimest<-VAR(vardat,p=2,type="const",season=NULL,exogen=NULL)
##Alternatively, selection according to AIC
varsimest<-VAR(vardat,type="const",lag.max=3,ic="SC")
##Checking the roots
roots <- roots(varsimest, modulus=TRUE)
##testing serial correlation
args(serial.test)
##Portmanteau-Test
var2c.serial<-serial.test(varsimest,lags.pt=16,type="PT.asymptotic")
var2c.serial
plot(var2c.serial,names="y1")
plot(var2c.serial,names="y2")
##testing heteroscedasticity
args(arch.test)
var2c.arch<-arch.test(varsimest,lags.multi=5,multivariate.only=TRUE)
var2c.arch
##testing for normality
args(normality.test)
var2c.norm<-normality.test(varsimest,multivariate.only=TRUE)
var2c.norm
##class and methods for diganostic tests
class(var2c.serial)
class(var2c.arch)
class(var2c.norm)
methods(class="varcheck")
##Plot of objects "varcheck"
args(vars:::plot.varcheck)
plot(var2c.serial,names="y1")
##Stability tests
reccusum <- stability(varsimest,type = "OLS-CUSUM")
fluctuation <- stability(varsimest,type = "fluctuation")
plot(reccusum)
##Causality Tests
## Granger and instantaneous causality
var.causal <- causality(varsimest,cause = "y2")
##Forecasting objects of class varest
args(vars:::predict.varest)
predictions <- predict(varsimest, n.ahead = 25,ci=0.95)
class(predictions)
args(vars:::plot.varprd)
##Plot of predictions for y1
plot(predictions, names = "y1")
fanchart(predictions, names = "y1")
##Fanchart for y2
args(fanchart)
fanchart(predictions, names = "y2")
##Impulse response analysis1
irf.y1 <- irf(varsimest, impulse = "y1", response = "y2", n.ahead = 10,
ortho = FALSE, cumulative = FALSE, boot = FALSE, seed = 12345)
args(vars:::plot.varirf)
plot(irf.y1)
irf.y2 <- irf(varsimest,impulse= "y2", response= "y1", n.ahead = 10,
ortho= TRUE, cumulative= TRUE, boot = FALSE, seed = 12345)
plot(irf.y2)
irf.y2 <- irf(varsimest,impulse= "y2", n.ahead = 20,
ortho= TRUE, boot = TRUE, seed = 12345)
plot(irf.y2)
##Forecast error variance decoposition
fevd.var2 <- fevd(varsimest, n.ahead = 10)
args(vars:::plot.varfevd)
plot(fevd.var2, addbars = 2)
## A-model
Apoly <- array(c(1.0, -0.5, 0.3, 0.8,
0.2, 0.1, -0.7, -0.2,
0.7, 1, 0.5, -0.3),
c(3,2,2))
##Setting covariance to identity-matrix
B <- diag(2)
##Gnerating the VAR(2) model
svarA <- ARMA(A = Apoly, B = B)
##Simulating 500 observations
svarsim <- simulate(svarA, sampleT = 500, rng = list(seed = c(123456)))
##Obtaing the generated series
svardat <- matrix(svarsim$output, nrow = 500, ncol = 2)
colnames(svardat) <- c("y1","y2")
##Estimating the VAR
varest<- VAR(svardat, p = 2, type = "none")
##Setting up matrices for A-model
Amat <- diag(2)
Amat[2, 1] <- NA
Amat[1, 2] <- NA
##Estiating the SVAR A-type by direct maximisation of the log-likelihood
args(SVAR)
View(svardat)
varest''
varest
Amat <- diag(2)
View(Amat)
Amat[2, 1] <- NA
Amat[1, 2] <- NA
View(Amat)
args(SVAR)
svar.A <- SVAR(varest, estmethod = "direct", Amat = Amat, hessian = TRUE)
svar.A
?SVAR
svar.A$A
amat <- diag(4)
diag(amat) <- NA
amat[2, 1] <- NA
amat[4, 1] <- NA
View(amat)
Amat <- diag(2)
Amat[2, 1] <- NA
View(Amat)
svar.A <- SVAR(varest, estmethod = "direct", Amat = Amat, hessian = TRUE)
svar.A <- SVAR(varest, estmethod = "scoring", Amat = Amat, hessian = TRUE)
svar.A$A
View(Amat)
irf.svara <- irf(svar.A, impulse = "y1", response = "y2", boot = FALSE)
plot(irf.svara)
irf.svara <- irf(svar.A, impulse = "y2", response = "y1", boot = FALSE)
args(vars:::plot.varirf)
plot(irf.svara)
svar.A$Ase
svar.A$A
svar.A$B
svar.A
svar.A$LRIM
svar.A$coef
summary(svar.A)
varest<- VAR(svardat, p = 2, type = "none")
##Setting up matrices for A-model
Amat <- diag(2)
Amat[2, 1] <- NA
Amat[1, 2] <- NA
##Estiating the SVAR A-type by direct maximisation of the log-likelihood
args(SVAR)
svar.A <- SVAR(varest, estmethod = "direct", Amat = Amat, hessian = TRUE)
summary(svar.A)
summary(varest)
svar.A$var
Amat <- diag(2)
Amat[1, 2] <- NA
View(Amat)
Amat <- diag(2)
Amat[2, 1] <- NA
View(Amat)
svar.A <- SVAR(varest, estmethod = "scoring", Amat = Amat, hessian = TRUE)
svar.A$var
Apoly<-array(c(1,-0.7, 0,-0.2,
0,-0.2, 1,-0.7),c(2,2,2))
##Setting Covariance to identity-matrix
B<-diag(2)
##Generating the VAR(2) model
var2<-ARMA(A=Apoly,B=B)
##Simulating 500 observations
varsim<-simulate(var2,sampleT=500,noise=list(w=matrix(rnorm(1000),
nrow=500,ncol=2)),rng=list(seed=c(123456)))
##Obtaining the generated series
vardat<-matrix(varsim$output,nrow=500,ncol=2)
colnames(vardat)<-c("y1","y2")
View(vardat)
##Plotting the series
plot.ts(vardat,main="",xlab="")
##Determining an appropriate lag-order
infocrit<-VARselect(vardat,lag.max=3,type="const")
##Estimating the model
varsimest<-VAR(vardat,p=1,type="none",season=NULL,exogen=NULL)
varsimest
roots <- roots(varsimest, modulus=TRUE)
##Impulse response analysis1
irf.y1 <- irf(varsimest, impulse = "y1", response = "y2", n.ahead = 10,
ortho = FALSE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
##Impulse response analysis1
irf.y1 <- irf(varsimest, impulse = "y1", n.ahead = 20,
ortho = FALSE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
irf.y1 <- irf(varsimest, n.ahead = 20,
ortho = FALSE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
irf.y1 <- irf(varsimest, impulse = "y1", n.ahead = 20,
ortho = TRUE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
irf.y1 <- irf(varsimest, impulse = "y1", n.ahead = 20,
ortho = FALSE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
##Impulse response analysis1
irf.y1 <- irf(varsimest, impulse = "y1", n.ahead = 20,
ortho = FALSE, cumulative = TRUE, boot = FALSE, seed = 12345)
plot(irf.y1)
##Impulse response analysis1
irf.y1 <- irf(varsimest, impulse = "y2", n.ahead = 20,
ortho = FALSE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
?irf
##Impulse response analysis1
irf.y1 <- irf(varsimest, impulse = "y2", n.ahead = 20,
ortho = TRUE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
irf.y1 <- irf(varsimest, n.ahead = 20,
ortho = TRUE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
B[2, 1] <- 0.8
##Generating the VAR(2) model
var2<-ARMA(A=Apoly,B=B)
##Simulating 500 observations
varsim<-simulate(var2,sampleT=500,noise=list(w=matrix(rnorm(1000),
nrow=500,ncol=2)),rng=list(seed=c(123456)))
##Obtaining the generated series
vardat<-matrix(varsim$output,nrow=500,ncol=2)
colnames(vardat)<-c("y1","y2")
##Plotting the series
plot.ts(vardat,main="",xlab="")
##Estimating the model
varsimest<-VAR(vardat,p=1,type="none",season=NULL,exogen=NULL)
varsimest
##Impulse response analysis1
irf.y1 <- irf(varsimest, n.ahead = 20,
ortho = TRUE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
B[1, 2] <- 0.8
View(B)
##Generating the VAR(2) model
var2<-ARMA(A=Apoly,B=B)
##Simulating 500 observations
varsim<-simulate(var2,sampleT=500,noise=list(w=matrix(rnorm(1000),
nrow=500,ncol=2)),rng=list(seed=c(123456)))
##Obtaining the generated series
vardat<-matrix(varsim$output,nrow=500,ncol=2)
colnames(vardat)<-c("y1","y2")
##Plotting the series
plot.ts(vardat,main="",xlab="")
##Estimating the model
varsimest<-VAR(vardat,p=1,type="none",season=NULL,exogen=NULL)
##Impulse response analysis1
irf.y1 <- irf(varsimest, n.ahead = 20,
ortho = TRUE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
##Impulse response analysis1
irf.y1 <- irf(varsimest, n.ahead = 20,
ortho = FALSE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
B<-diag(2)
B[1, 2] <- 0.8
##Generating the VAR(2) model
var2<-ARMA(A=Apoly,B=B)
##Simulating 500 observations
varsim<-simulate(var2,sampleT=500,noise=list(w=matrix(rnorm(1000),
nrow=500,ncol=2)),rng=list(seed=c(123456)))
##Obtaining the generated series
vardat<-matrix(varsim$output,nrow=500,ncol=2)
colnames(vardat)<-c("y1","y2")
##Plotting the series
plot.ts(vardat,main="",xlab="")
##Estimating the model
varsimest<-VAR(vardat,p=1,type="none",season=NULL,exogen=NULL)
##Impulse response analysis1
irf.y1 <- irf(varsimest, n.ahead = 20,
ortho = FALSE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
View(B)
##Impulse response analysis1
irf.y1 <- irf(varsimest, n.ahead = 20,
ortho = TRUE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
varsimest<-VAR(vardat[,c(2,1)],p=1,type="none",season=NULL,exogen=NULL)
##Impulse response analysis1
irf.y1 <- irf(varsimest, n.ahead = 20,
ortho = TRUE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
##Impulse response analysis1
irf.y1 <- irf(varsimest, n.ahead = 20, impulse = "y2", response = "y1",
ortho = TRUE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
irf.y1 <- irf(varsimest, n.ahead = 20, impulse = "y2", response = "y2",
ortho = TRUE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
##Estimating the model
varsimest<-VAR(vardat,p=1,type="none",season=NULL,exogen=NULL)
##Impulse response analysis1
irf.y1 <- irf(varsimest, n.ahead = 20, impulse = "y2", response = "y2",
ortho = TRUE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
##Impulse response analysis1
irf.y1 <- irf(varsimest, n.ahead = 20, impulse = "y2", response = "y1",
ortho = TRUE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
?irf
##Impulse response analysis1
irf.y1 <- irf(varsimest, n.ahead = 20
ortho = FALSE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
irf.y1 <- irf(varsimest, n.ahead = 20,
ortho = FALSE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
##Estimating the model
varsimest<-VAR(vardat[,c(2,1)],p=1,type="none",season=NULL,exogen=NULL)
##Impulse response analysis1
irf.y1 <- irf(varsimest, n.ahead = 20,
ortho = FALSE, cumulative = FALSE, boot = FALSE, seed = 12345)
plot(irf.y1)
set.seed(189)
n = 2000
# sale dates range from 0-10
# drawn uniformly from all possible time0, time1 combinations with time0<time1
tmat <- expand.grid(seq(0,10), seq(0,10))
tmat <- tmat[tmat[,1]<tmat[,2], ]
tobs <- sample(seq(1:nrow(tmat)),n,replace=TRUE)
time0 <- tmat[tobs,1]
time1 <- tmat[tobs,2]
timesale <- time1-time0
table(timesale)
View(tmat)
# constant variance; index ranges from 0 at time 0 to 1 at time 10
y0 <- time0/10 + rnorm(n,0,.2)
y1 <- time1/10 + rnorm(n,0,.2)
fit <- repsale(price0=y0, price1=y1, time0=time0, time1=time1)
library(McSpatial)
fit <- repsale(price0=y0, price1=y1, time0=time0, time1=time1)
# variance rises with timesale
# var(u0) = .2^2; var(u1) = (.2 + timesale/10)^2
# var(u1-u0) = var(u0) + var(u1) = 2*(.2^2) + .4*timesale/10 + (timesale^2)/100
y0 <- time0/10 + rnorm(n,0,.2)
y1 <- time1/10 + rnorm(n,0,.2+timesale/10)
par(ask=TRUE)
fit <- repsale(price0=y0, price1=y1, time0=time0, time1=time1)
fit <- repsale(price0=y0, price1=y1, time0=time0, time1=time1, stage3="abs")
timesale2 <- timesale^2
fit <- repsale(price0=y0, price1=y1, time0=time0, time1=time1, stage3="square",
stage3_xlist=~timesale+timesale2)
library(tempdisagg)
install.packages("tempdisagg")
library(tempdisagg)
?td
demo(tempdisagg)
##=====================##
## READING IN THE DATA ##
##=====================##
suppressMessages(library(zoo))
suppressMessages(library(ggplot2))
suppressMessages(library(plyr))
suppressMessages(library(dplyr))
suppressMessages(library(reshape2))
suppressMessages(library(stargazer))
suppressMessages(library(micEcon))
suppressMessages(library(quantreg))
suppressMessages(library(McSpatial))
suppressMessages(library(quantmod))
suppressMessages(library(xtable))
suppressMessages(library(scales))
suppressMessages(library(tseries))
suppressMessages(library(urca))
suppressMessages(library(mFilter))
setwd("C:\\Users\\Laurie\\OneDrive\\Documents\\BING\\Art Price Index\\R Code")
artdata <- read.csv("Auction database.csv", header=TRUE, sep=",",na.strings = "", skipNul = TRUE,
colClasses=c("character","numeric","numeric","numeric","numeric","factor","factor","factor","character",
"factor","factor","factor","character","factor","factor","factor","numeric","character",
"numeric","numeric","numeric","numeric","numeric","numeric"))
#Load pre-calculated dataset (for speed) from API_3.R
artdata <- read.csv("artdata_lnrep.csv", header=TRUE)
artdata$med_code <- factor(artdata$med_code, labels=c("NA","Drawing", "Watercolour", "Oil", "Acrylic", "Print/Woodcut",
"Mixed Media","Sculpture","Photography", "Other"))
#The result: index of average price per artist adjusted for quality, relative to the base artist
#It can replace the artist dummies as a continuous variable in a second regression of equation 1
#Plot artist reputation index and prices
artplot <- subset(artdata, med_code!="NA")
g <- ggplot(artplot, aes(x=lnrep, y=lnprice))
g <- g + geom_point(size = 2, alpha = 0.5, aes(colour = med_code))
g <- g + ylab("log of Price")
g <- g + xlab("log of Artist Reputation")
g <- g + labs(colour = "Medium")
g <- g + guides(colour = guide_legend(override.aes = list(size=5)))
g
full_model <- function(artdata, list_expl_vars=c("lnarea","ah_code","med_code","lnsculpt_area","dum_signed", "dum_dated",
"nr_works","artist","timedummy")) {
modeldata <- artdata
expl_vars <- as.formula(paste("lnprice~",paste(list_expl_vars,collapse="+")))
model_all <- lm(expl_vars, data=modeldata)
time_results <- summary(model_all)$coefficients[grepl("time", rownames(summary(model_all)$coefficients)),1]
time_results <- as.data.frame(time_results)
time_results$index_all <- exp(time_results$time_results)*100
return(time_results)
}
#Full model for regression results
list_expl_vars <- c("lnarea","ah_code","med_code","lnsculpt_area","dum_signed","dum_dated",
"nr_works","lnrep","timedummy")
expl_vars <- as.formula(paste("lnprice~",paste(list_expl_vars,collapse="+")))
modeldata <- artdata
model <- lm(expl_vars, data=modeldata)
#do the same but expand it to not match by title or authenticity dummies
#check for duplicates (how many)
sum(duplicated(artdata[,c("artist","med_code","area","nr_works")]))
rsartdata2 <- artdata[allDup(artdata[,c("artist","med_code","area","nr_works")]),]
rsartdata2 <- transform(rsartdata2, id = as.numeric(interaction(artist,med_code,factor(area),factor(nr_works), drop=TRUE)))
repdata2 <- cbind(repsaledata(rsartdata2$lnprice,rsartdata2$counter,rsartdata2$id),
repsaledata(rsartdata2$ah_code,rsartdata2$counter,rsartdata2$id)[,4:5],
repsaledata(rsartdata2$dum_signed,rsartdata2$counter,rsartdata2$id)[,4:5],
repsaledata(rsartdata2$dum_dated,rsartdata2$counter,rsartdata2$id)[,4:5])
repdata2 <- repdata2[complete.cases(repdata2),]
colnames(repdata2) <- c("id","time0","time1","price0","price1","ah_code0","ah_code1","sign0","sign1","date0","date1")
dy <- repdata2$price1 - repdata2$price0
dsign <- repdata2$sign1 - repdata2$sign0
ddate <- repdata2$date1 - repdata2$date0
ah0 <- model.matrix(~repdata2$ah_code0)
ah1 <- model.matrix(~repdata2$ah_code1)
dah <- ah1 - ah0
timevar <- levels(factor(c(repdata2$time0, repdata2$time1)))
nt = length(timevar)
n = length(dy)
xmat <- array(0, dim = c(n, nt - 1))
for (j in seq(1 + 1, nt)) {
xmat[,j-1] <- ifelse(repdata2$time1 == timevar[j], 1, xmat[,j-1])
xmat[,j-1] <- ifelse(repdata2$time0 == timevar[j],-1, xmat[,j-1])
}
colnames(xmat) <- paste("Time", seq(1 + 1, nt))
ps.RS <- lm(dy ~ dah + dsign + ddate + xmat + 0)
allDup <- function(value) {  #identify duplicated values
duplicated(value) | duplicated(value, fromLast = TRUE)
}
#do the same but expand it to not match by title or authenticity dummies
#check for duplicates (how many)
sum(duplicated(artdata[,c("artist","med_code","area","nr_works")]))
rsartdata2 <- artdata[allDup(artdata[,c("artist","med_code","area","nr_works")]),]
rsartdata2 <- transform(rsartdata2, id = as.numeric(interaction(artist,med_code,factor(area),factor(nr_works), drop=TRUE)))
repdata2 <- cbind(repsaledata(rsartdata2$lnprice,rsartdata2$counter,rsartdata2$id),
repsaledata(rsartdata2$ah_code,rsartdata2$counter,rsartdata2$id)[,4:5],
repsaledata(rsartdata2$dum_signed,rsartdata2$counter,rsartdata2$id)[,4:5],
repsaledata(rsartdata2$dum_dated,rsartdata2$counter,rsartdata2$id)[,4:5])
repdata2 <- repdata2[complete.cases(repdata2),]
colnames(repdata2) <- c("id","time0","time1","price0","price1","ah_code0","ah_code1","sign0","sign1","date0","date1")
dy <- repdata2$price1 - repdata2$price0
dsign <- repdata2$sign1 - repdata2$sign0
ddate <- repdata2$date1 - repdata2$date0
ah0 <- model.matrix(~repdata2$ah_code0)
ah1 <- model.matrix(~repdata2$ah_code1)
dah <- ah1 - ah0
timevar <- levels(factor(c(repdata2$time0, repdata2$time1)))
nt = length(timevar)
n = length(dy)
xmat <- array(0, dim = c(n, nt - 1))
for (j in seq(1 + 1, nt)) {
xmat[,j-1] <- ifelse(repdata2$time1 == timevar[j], 1, xmat[,j-1])
xmat[,j-1] <- ifelse(repdata2$time0 == timevar[j],-1, xmat[,j-1])
}
colnames(xmat) <- paste("Time", seq(1 + 1, nt))
ps.RS <- lm(dy ~ dah + dsign + ddate + xmat + 0)
model <- ps.RS
resids <- rstandard(model)
hist(resids)
qqnorm(resids)
qqline(resids)
qqPlot(model, main="QQ Plot")
library(car)
# Normality of Residuals
# qq plot for studentized resid
qqPlot(model, main="QQ Plot")
library(MASS)
sresid <- studres(model)
hist(sresid, freq=FALSE,
main="Distribution of Studentized Residuals")
xfit<-seq(min(sresid),max(sresid),length=40)
yfit<-dnorm(xfit)
lines(xfit, yfit)
jarque.bera.test(resids)
shapiro.test(resids)
ncvTest(model)
spreadLevelPlot(model)
# Global test of model assumptions
library(gvlma)
gvmodel <- gvlma(fit)
summary(gvmodel)
install.packages("gvlma")
# Global test of model assumptions
library(gvlma)
gvmodel <- gvlma(fit)
summary(gvmodel)
gvmodel <- gvlma(model)
summary(gvmodel)
